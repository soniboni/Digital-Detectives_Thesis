{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a6c61a",
   "metadata": {},
   "source": [
    "# 1: Data Import and Initial Exploration (Raw Data) \n",
    "This first notebook is for getting the data into memory and a quick first look."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21770230",
   "metadata": {},
   "source": [
    "## Data Import & Initial Exploration (Raw Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a3b9b4",
   "metadata": {},
   "source": [
    "### 1. Code Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5361c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set display options for better data visibility\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x) # Keeps floats clean\n",
    "\n",
    "# Define file paths (adjust these to your actual file names and locations)\n",
    "# Assuming you've already parsed LogFile and UsnJrnl into a clean CSV format\n",
    "# This is a crucial step *before* this notebook for getting structured data.\n",
    "log_file_path = 'data/raw/09-PE-LogFile.csv'\n",
    "usnjrnl_path = 'data/raw/09-PE-UsnJrnl.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae22aa2",
   "metadata": {},
   "source": [
    "### 2. Import the CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb79e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogFile data loaded successfully. Shape: (25688, 13)\n",
      "UsnJrnl data loaded successfully. Shape: (249559, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "try:\n",
    "    df_log = pd.read_csv(log_file_path)\n",
    "    print(f\"LogFile data loaded successfully. Shape: {df_log.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: LogFile CSV not found at {log_file_path}\")\n",
    "\n",
    "try:\n",
    "    df_usn = pd.read_csv(usnjrnl_path)\n",
    "    print(f\"UsnJrnl data loaded successfully. Shape: {df_usn.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: UsnJrnl CSV not found at {usnjrnl_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f9448",
   "metadata": {},
   "source": [
    "### 3. Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c162dbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LogFile Initial Inspection ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSN</th>\n",
       "      <th>EventTime(UTC+8)</th>\n",
       "      <th>Event</th>\n",
       "      <th>Detail</th>\n",
       "      <th>File/Directory Name</th>\n",
       "      <th>Full Path</th>\n",
       "      <th>CreationTime</th>\n",
       "      <th>ModifiedTime</th>\n",
       "      <th>MFTModifiedTime</th>\n",
       "      <th>AccessedTime</th>\n",
       "      <th>Redo</th>\n",
       "      <th>Target VCN</th>\n",
       "      <th>Cluster Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006785113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File Deletion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UDB-User23847576+RemoteGraph.sql-journal</td>\n",
       "      <td>\\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...</td>\n",
       "      <td>12/25/23 22:19:43</td>\n",
       "      <td>12/25/23 22:19:48</td>\n",
       "      <td>12/25/23 22:19:48</td>\n",
       "      <td>12/25/23 22:19:48</td>\n",
       "      <td>Deallocate File Record Segment</td>\n",
       "      <td>0x2FB7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10006785298</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>File Creation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UDB-User23847576+LocalStorage.sql-journal</td>\n",
       "      <td>\\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>Initialize File Record Segment</td>\n",
       "      <td>0x2FB7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10006785525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Writing Content of Resident File</td>\n",
       "      <td>Writing Size : 512</td>\n",
       "      <td>UDB-User23847576+LocalStorage.sql-journal</td>\n",
       "      <td>\\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x2FB7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10006786167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Updating Modified Time</td>\n",
       "      <td>ModifiedTime : 2023-12-25 22:19:20 -&gt; 2023-12-...</td>\n",
       "      <td>UDB-User23847576+LocalStorage.sql &lt;Guessed&gt;</td>\n",
       "      <td>\\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x6E74</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10006786545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File Deletion</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UDB-User23847576+LocalStorage.sql-journal</td>\n",
       "      <td>\\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>Deallocate File Record Segment</td>\n",
       "      <td>0x2FB7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LSN   EventTime(UTC+8)                             Event                                             Detail                          File/Directory Name                                          Full Path       CreationTime       ModifiedTime    MFTModifiedTime       AccessedTime                            Redo Target VCN  Cluster Index\n",
       "0  10006785113                NaN                     File Deletion                                                NaN     UDB-User23847576+RemoteGraph.sql-journal  \\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...  12/25/23 22:19:43  12/25/23 22:19:48  12/25/23 22:19:48  12/25/23 22:19:48  Deallocate File Record Segment     0x2FB7              6\n",
       "1  10006785298  12/25/23 22:19:50                     File Creation                                                NaN    UDB-User23847576+LocalStorage.sql-journal  \\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...  12/25/23 22:19:50  12/25/23 22:19:50  12/25/23 22:19:50  12/25/23 22:19:50  Initialize File Record Segment     0x2FB7              6\n",
       "2  10006785525                NaN  Writing Content of Resident File                                 Writing Size : 512    UDB-User23847576+LocalStorage.sql-journal  \\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...                NaN                NaN                NaN                NaN           Update Resident Value     0x2FB7              6\n",
       "3  10006786167                NaN            Updating Modified Time  ModifiedTime : 2023-12-25 22:19:20 -> 2023-12-...  UDB-User23847576+LocalStorage.sql <Guessed>  \\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...                NaN                NaN                NaN                NaN           Update Resident Value     0x6E74              6\n",
       "4  10006786545                NaN                     File Deletion                                                NaN    UDB-User23847576+LocalStorage.sql-journal  \\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...  12/25/23 22:19:50  12/25/23 22:19:50  12/25/23 22:19:50  12/25/23 22:19:50  Deallocate File Record Segment     0x2FB7              6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25688 entries, 0 to 25687\n",
      "Columns: 13 entries, LSN to Cluster Index\n",
      "dtypes: int64(2), object(11)\n",
      "memory usage: 17.7 MB\n",
      "\n",
      "--- UsnJrnl Initial Inspection ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp(UTC+8)</th>\n",
       "      <th>USN</th>\n",
       "      <th>File/Directory Name</th>\n",
       "      <th>FullPath</th>\n",
       "      <th>EventInfo</th>\n",
       "      <th>SourceInfo</th>\n",
       "      <th>FileAttribute</th>\n",
       "      <th>Carving Flag</th>\n",
       "      <th>FileReferenceNumber</th>\n",
       "      <th>ParentFileReferenceNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677721600</td>\n",
       "      <td>amd64_windows-shield-provider.resources_31bf38...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Directory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x000100000007BDEC</td>\n",
       "      <td>0x000300000002CC20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677721848</td>\n",
       "      <td>amd64_windows-shield-provider.resources_31bf38...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x0001000000073F99</td>\n",
       "      <td>0x000300000002CC20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677722120</td>\n",
       "      <td>securityhealthagent.dll.mui</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x000100000007BE07</td>\n",
       "      <td>0x000100000007BE06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677722240</td>\n",
       "      <td>windowsdefendersecuritycenter.adml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x000100000007D7AA</td>\n",
       "      <td>0x000100000007BE06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677722368</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Directory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x000100000007BE06</td>\n",
       "      <td>0x000100000007BE05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TimeStamp(UTC+8)         USN                                File/Directory Name FullPath                   EventInfo SourceInfo FileAttribute  Carving Flag FileReferenceNumber ParentFileReferenceNumber\n",
       "0  12/25/23 16:47:05  1677721600  amd64_windows-shield-provider.resources_31bf38...      NaN  File_Closed / File_Deleted     Normal     Directory           NaN  0x000100000007BDEC        0x000300000002CC20\n",
       "1  12/25/23 16:47:05  1677721848  amd64_windows-shield-provider.resources_31bf38...      NaN  File_Closed / File_Deleted     Normal        Normal           NaN  0x0001000000073F99        0x000300000002CC20\n",
       "2  12/25/23 16:47:05  1677722120                        securityhealthagent.dll.mui      NaN  File_Closed / File_Deleted     Normal        Normal           NaN  0x000100000007BE07        0x000100000007BE06\n",
       "3  12/25/23 16:47:05  1677722240                 windowsdefendersecuritycenter.adml      NaN  File_Closed / File_Deleted     Normal        Normal           NaN  0x000100000007D7AA        0x000100000007BE06\n",
       "4  12/25/23 16:47:05  1677722368                                                  f      NaN  File_Closed / File_Deleted     Normal     Directory           NaN  0x000100000007BE06        0x000100000007BE05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249559 entries, 0 to 249558\n",
      "Columns: 10 entries, TimeStamp(UTC+8) to ParentFileReferenceNumber\n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 143.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Check LogFile structure\n",
    "print(\"\\n--- LogFile Initial Inspection ---\")\n",
    "display(df_log.head())\n",
    "df_log.info(verbose=False, memory_usage='deep')\n",
    "\n",
    "# Check UsnJrnl structure\n",
    "print(\"\\n--- UsnJrnl Initial Inspection ---\")\n",
    "display(df_usn.head())\n",
    "df_usn.info(verbose=False, memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb4332",
   "metadata": {},
   "source": [
    "## LogFile Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbfd536",
   "metadata": {},
   "source": [
    "### 1. Standardize Column Names\n",
    "First, we must standardize the column names for uniformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5fffee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New LogFile Columns: ['lsn', 'eventtime', 'event', 'detail', 'filedirectoryname', 'fullpath', 'creationtime', 'modifiedtime', 'mftmodifiedtime', 'accessedtime', 'redo', 'targetvcn', 'clusterindex']\n"
     ]
    }
   ],
   "source": [
    "# 1. Standardize column names: lowercase, remove special characters/parentheses, replace spaces with underscores.\n",
    "df_log.columns = (\n",
    "    df_log.columns\n",
    "    .str.lower()\n",
    "    .str.replace(r'\\(.*?\\)', '', regex=True) # Remove anything in parentheses (like '(UTC+8)')\n",
    "    .str.replace('[^a-z0-9_]', '', regex=True) # Remove other non-alphanumeric chars (like slashes)\n",
    "    .str.replace(' ', '_', regex=False)\n",
    "    .str.replace('__', '_', regex=False) # Handle double underscores if they result\n",
    "    .str.strip('_') # Remove leading/trailing underscores\n",
    ")\n",
    "\n",
    "# Display the new, clean column names\n",
    "print(\"New LogFile Columns:\", df_log.columns.tolist())\n",
    "\n",
    "# Rename specific columns for clarity if needed (e.g., 'eventdetail' is a good name already)\n",
    "# If your column is now just 'eventdetail', you are good to go.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef789a1e",
   "metadata": {},
   "source": [
    "### 2. Addressing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ff6170",
   "metadata": {},
   "source": [
    "#### 2.1 Check for Missing Values for all columns\n",
    "Now we can accurately check for missing values in all columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af7b1ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for LogFile (Total Rows: 25688) ---\n",
      "--------------------------------------------------\n",
      "Columns with Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>detail</th>\n",
       "      <td>18521</td>\n",
       "      <td>72.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventtime</th>\n",
       "      <td>15272</td>\n",
       "      <td>59.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event</th>\n",
       "      <td>12274</td>\n",
       "      <td>47.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creationtime</th>\n",
       "      <td>7346</td>\n",
       "      <td>28.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modifiedtime</th>\n",
       "      <td>7346</td>\n",
       "      <td>28.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mftmodifiedtime</th>\n",
       "      <td>7346</td>\n",
       "      <td>28.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accessedtime</th>\n",
       "      <td>7346</td>\n",
       "      <td>28.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullpath</th>\n",
       "      <td>2004</td>\n",
       "      <td>7.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filedirectoryname</th>\n",
       "      <td>1008</td>\n",
       "      <td>3.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Missing Count  Missing Percentage\n",
       "detail                     18521              72.100\n",
       "eventtime                  15272              59.450\n",
       "event                      12274              47.780\n",
       "creationtime                7346              28.600\n",
       "modifiedtime                7346              28.600\n",
       "mftmodifiedtime             7346              28.600\n",
       "accessedtime                7346              28.600\n",
       "fullpath                    2004               7.800\n",
       "filedirectoryname           1008               3.920"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of entries\n",
    "total_rows = len(df_log)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for LogFile (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_log.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"🎉 Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d6bfa2",
   "metadata": {},
   "source": [
    "##### 2.1.1 Removing empty values on event\n",
    "We must remove rows with empty rows in the **event** column because this information provides the causation (the file action) that links timestamps together. For a thesis on timestomping detection, removing eventless records ensures the ML model only trains on high-integrity data, preventing unreliable feature creation and minimizing the risk of low-confidence or false-positive reports in your prototype's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b154d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LogFile Event Detail Cleaning ---\n",
      "Total rows before cleaning: 25688\n",
      "Rows with missing 'event': 12274\n",
      "Percentage missing: 47.78%\n",
      "--------------------------------------------------\n",
      "✅ Successfully dropped 12274 rows.\n",
      "Rows remaining in LogFile: 13414\n"
     ]
    }
   ],
   "source": [
    "# 1. Identify the critical column\n",
    "event_col = 'event'\n",
    "\n",
    "# 2. Check for missing values in the 'event' column\n",
    "total_rows = len(df_log)\n",
    "missing_event_count = df_log[event_col].isna().sum()\n",
    "\n",
    "print(f\"--- LogFile Event Detail Cleaning ---\")\n",
    "print(f\"Total rows before cleaning: {total_rows}\")\n",
    "print(f\"Rows with missing '{event_col}': {missing_event_count}\")\n",
    "print(f\"Percentage missing: {missing_event_count / total_rows * 100:.2f}%\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 3. Drop rows where the 'event' column is NaN\n",
    "# We use inplace=True to modify the DataFrame directly\n",
    "if missing_event_count > 0:\n",
    "    df_log.dropna(subset=[event_col], inplace=True)\n",
    "    \n",
    "    # 4. Verification\n",
    "    rows_dropped = missing_event_count\n",
    "    rows_remaining = len(df_log)\n",
    "    \n",
    "    print(f\"✅ Successfully dropped {rows_dropped} rows.\")\n",
    "    print(f\"Rows remaining in LogFile: {rows_remaining}\")\n",
    "else:\n",
    "    print(\"Column 'event' is fully populated. No rows were dropped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac06ea",
   "metadata": {},
   "source": [
    "##### 2.1.2 Dropping detail column \n",
    "Retaining it would require complex and inefficient Natural Language Processing (NLP) techniques, whereas all necessary context is already captured by the event and timestamp columns, justifying its removal for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68fe3afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully dropped the 'detail' column.\n",
      "Columns remaining: ['lsn', 'eventtime', 'event', 'filedirectoryname', 'fullpath', 'creationtime', 'modifiedtime', 'mftmodifiedtime', 'accessedtime', 'redo', 'targetvcn', 'clusterindex']\n"
     ]
    }
   ],
   "source": [
    "# Define the column to be dropped\n",
    "detail_col = 'detail'\n",
    "\n",
    "if detail_col in df_log.columns:\n",
    "    # Drop the 'detail' column permanently\n",
    "    df_log.drop(columns=[detail_col], inplace=True)\n",
    "    \n",
    "    print(f\"✅ Successfully dropped the '{detail_col}' column.\")\n",
    "    print(f\"Columns remaining: {list(df_log.columns)}\")\n",
    "else:\n",
    "    print(f\"Column '{detail_col}' was already dropped or not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1cc6ae",
   "metadata": {},
   "source": [
    "#### 2.2 Check for Missing Values for all columns\n",
    "Checking if the dropped values of **event** is effective, and address more columns to clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b10059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for LogFile (Total Rows: 13414) ---\n",
      "--------------------------------------------------\n",
      "Columns with Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>creationtime</th>\n",
       "      <td>7346</td>\n",
       "      <td>54.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modifiedtime</th>\n",
       "      <td>7346</td>\n",
       "      <td>54.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mftmodifiedtime</th>\n",
       "      <td>7346</td>\n",
       "      <td>54.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accessedtime</th>\n",
       "      <td>7346</td>\n",
       "      <td>54.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventtime</th>\n",
       "      <td>6485</td>\n",
       "      <td>48.350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullpath</th>\n",
       "      <td>1823</td>\n",
       "      <td>13.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filedirectoryname</th>\n",
       "      <td>1008</td>\n",
       "      <td>7.510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Missing Count  Missing Percentage\n",
       "creationtime                7346              54.760\n",
       "modifiedtime                7346              54.760\n",
       "mftmodifiedtime             7346              54.760\n",
       "accessedtime                7346              54.760\n",
       "eventtime                   6485              48.350\n",
       "fullpath                    1823              13.590\n",
       "filedirectoryname           1008               7.510"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of entries\n",
    "total_rows = len(df_log)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for LogFile (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_log.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"🎉 Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa22248",
   "metadata": {},
   "source": [
    "##### 2.2.1 eventtime Imputation starting with creationtime \n",
    "We are imputing the missing **eventtime** to ensure every record has a chronological anchor, which is essential for sequencing events and calculating time deltas for the ML model. We use the reliable timestamps (**creationtime**, **modifiedtime**, and **mftmodifiedtime**) for this, but intentionally exclude **accessedtime** from imputation because its high unreliability risks corrupting the logical chronological order. We keep the **accessedtime** column as a separate feature because its inconsistency or presence might still serve as a detectable signal that the ML model can learn to associate with anomalous (timestomped) file activity. \n",
    "\n",
    "In the first layer of imputation, we start with creationtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "388ac19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing 'eventtime' before imputation: 6485\n",
      "Rows imputed (filled): 1753\n",
      "Remaining missing 'eventtime' after imputation: 4732\n",
      "\n",
      "Note: Some rows still have missing 'eventtime'. This means their corresponding 'creationtime' was also missing.\n",
      "\n",
      "Sample of rows (first 5) to show the filled column:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventtime</th>\n",
       "      <th>creationtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/25/23 22:19:43</td>\n",
       "      <td>12/25/23 22:19:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           eventtime       creationtime\n",
       "0  12/25/23 22:19:43  12/25/23 22:19:43\n",
       "1  12/25/23 22:19:50  12/25/23 22:19:50\n",
       "2                NaN                NaN\n",
       "3                NaN                NaN\n",
       "4  12/25/23 22:19:50  12/25/23 22:19:50"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Standardize column names (if not done in the previous cell to ensure reliability)\n",
    "df_log.columns = (\n",
    "    df_log.columns\n",
    "    .str.lower()\n",
    "    .str.replace(r'\\(.*?\\)', '', regex=True) # Remove anything in parentheses\n",
    "    .str.replace('[^a-z0-9_]', '', regex=True)\n",
    "    .str.replace(' ', '_', regex=False)\n",
    "    .str.strip('_')\n",
    ")\n",
    "\n",
    "# Define the columns (using the exact names found: 'eventtime' and 'creationtime')\n",
    "event_time_col = 'eventtime'\n",
    "creation_time_col = 'creationtime'\n",
    "\n",
    "# 2. Check current state of eventtime\n",
    "initial_missing_count = df_log[event_time_col].isna().sum()\n",
    "print(f\"Rows with missing '{event_time_col}' before imputation: {initial_missing_count}\")\n",
    "\n",
    "if initial_missing_count > 0:\n",
    "    # 3. Impute missing 'eventtime' using 'creationtime'\n",
    "    # We use .fillna() and provide the entire 'creationtime' Series as the filling value.\n",
    "    df_log[event_time_col] = df_log[event_time_col].fillna(df_log[creation_time_col])\n",
    "\n",
    "    # 4. Verification Check\n",
    "    final_missing_count = df_log[event_time_col].isna().sum()\n",
    "    rows_imputed = initial_missing_count - final_missing_count\n",
    "\n",
    "    print(f\"Rows imputed (filled): {rows_imputed}\")\n",
    "    print(f\"Remaining missing '{event_time_col}' after imputation: {final_missing_count}\")\n",
    "    \n",
    "    if final_missing_count > 0:\n",
    "        print(\"\\nNote: Some rows still have missing 'eventtime'. This means their corresponding 'creationtime' was also missing.\")\n",
    "        # If necessary, we would drop these remaining rows in a later step if time data is non-negotiable.\n",
    "\n",
    "    # 5. Display a sample of imputed rows (where the value was previously NaN)\n",
    "    # This requires running the verification check on the original data, but we can show the fill-in effect:\n",
    "    print(\"\\nSample of rows (first 5) to show the filled column:\")\n",
    "    display(df_log[[event_time_col, creation_time_col]].head())\n",
    "\n",
    "else:\n",
    "    print(f\"Column '{event_time_col}' is already complete. No imputation was performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34784ac",
   "metadata": {},
   "source": [
    "##### 2.2.1.2 EventTime Further Adjustment: Timestamp existence checking & Imputation of Latest Available Time. \n",
    "If **creationtime** is also missing, use the latest of the remaining valid timestamps, except **accessedtime** for imputation. This is the most conservative estimate for the transaction commit time, avoiding the bias of timestomping. But we should check first if other timestamps are existing when creationtime isn't. If they don't we can drop the row as they don't exist any timestamps, thus no relevant data for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a052b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Conditional Early Drop ---\n",
      "Total rows where 'creationtime' is missing: 7346\n",
      "Rows where ALL 5 timestamps are ALSO missing: 4732\n",
      "Percentage of creationtime-missing rows where all others are also missing: 64.42%\n",
      "\n",
      "Removed 4732 rows that were missing ALL 5 timestamps.\n",
      "Rows remaining in LogFile: 8682\n",
      "\n",
      "--- Step 2: Imputation Priority 2 ---\n",
      "No further 'eventtime' NaNs found. Cleaning complete. ✅\n"
     ]
    }
   ],
   "source": [
    "# Define all relevant timestamp columns\n",
    "event_time_col = 'eventtime'\n",
    "creation_time_col = 'creationtime'\n",
    "# Note: accessedtime is NOT included in the reliable list for IMPUTATION, but it IS used for the initial drop check\n",
    "reliable_ntfs_timestamps = ['creationtime', 'modifiedtime', 'mftmodifiedtime'] \n",
    "all_time_cols = [event_time_col] + reliable_ntfs_timestamps + ['accessedtime'] # 5 total columns\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "## Step 1: Conditional Early Drop (Based on Forensic Pattern)\n",
    "# -------------------------------------------------------------\n",
    "print(\"--- Step 1: Conditional Early Drop ---\")\n",
    "\n",
    "# 1. Filter the DataFrame for rows where 'creationtime' is missing (NaN)\n",
    "creation_time_missing_df = df_log[df_log[creation_time_col].isna()]\n",
    "total_creation_time_missing = len(creation_time_missing_df)\n",
    "\n",
    "# 2. Check the condition: Are ALL 5 time columns missing in this subset?\n",
    "# This identifies rows that are truly time-less (missing eventtime, creationtime, modifiedtime, mftmodifiedtime, and accessedtime)\n",
    "all_time_missing_mask = df_log[all_time_cols].isna().all(axis=1)\n",
    "count_all_empty = all_time_missing_mask.sum()\n",
    "\n",
    "# 3. Report the compelling forensic finding (similar to your request)\n",
    "print(f\"Total rows where '{creation_time_col}' is missing: {total_creation_time_missing}\")\n",
    "\n",
    "# Only calculate percentage if there are missing creationtime rows AND they all align with the 'all empty' count\n",
    "if total_creation_time_missing > 0 and count_all_empty == total_creation_time_missing:\n",
    "    print(f\"Rows where ALL 5 timestamps are ALSO missing: {count_all_empty}\")\n",
    "    print(f\"Percentage of creationtime-missing rows where all others are also missing: 100.00%\")\n",
    "elif total_creation_time_missing > 0:\n",
    "    # If not 100%, show the actual percentage\n",
    "    percentage = (count_all_empty / total_creation_time_missing) * 100\n",
    "    print(f\"Rows where ALL 5 timestamps are ALSO missing: {count_all_empty}\")\n",
    "    print(f\"Percentage of creationtime-missing rows where all others are also missing: {percentage:.2f}%\")\n",
    "else:\n",
    "    print(\"No rows found where 'creationtime' is missing.\")\n",
    "\n",
    "\n",
    "if count_all_empty > 0:\n",
    "    # Drop these rows immediately\n",
    "    df_log.drop(df_log[all_time_missing_mask].index, inplace=True)\n",
    "    \n",
    "    print(f\"\\nRemoved {count_all_empty} rows that were missing ALL 5 timestamps.\")\n",
    "    print(f\"Rows remaining in LogFile: {len(df_log)}\")\n",
    "else:\n",
    "    print(\"No completely time-less rows found. Proceeding to imputation.\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "## Step 2: Imputation Priority 2 (Latest of Reliable Times)\n",
    "# -------------------------------------------------------------\n",
    "# Note: Imputation Priority 1 (eventtime with creationtime) is assumed to have run previously.\n",
    "print(\"\\n--- Step 2: Imputation Priority 2 ---\")\n",
    "remaining_missing_before = df_log[event_time_col].isna().sum()\n",
    "\n",
    "if remaining_missing_before > 0:\n",
    "    \n",
    "    # 1. Create a temporary 'LatestTime' column, using only the *reliable* subset\n",
    "    df_log['latest_reliable_time_temp'] = df_log[reliable_ntfs_timestamps].max(axis=1)\n",
    "\n",
    "    # 2. Fill the remaining missing 'eventtime' values with this latest available time\n",
    "    df_log[event_time_col] = df_log[event_time_col].fillna(df_log['latest_reliable_time_temp'])\n",
    "\n",
    "    # Calculate and report results\n",
    "    rows_imputed_p2 = remaining_missing_before - df_log[event_time_col].isna().sum()\n",
    "\n",
    "    print(f\"Imputed remaining 'eventtime' with the LATEST RELIABLE available time. Rows filled: {rows_imputed_p2}\")\n",
    "    \n",
    "    # Drop the temporary column\n",
    "    df_log.drop(columns=['latest_reliable_time_temp'], inplace=True)\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    ## Step 3: Final Clean-up (Drop residual empty records)\n",
    "    # -------------------------------------------------------------\n",
    "    final_missing_count = df_log[event_time_col].isna().sum()\n",
    "    print(\"\\n--- Step 3: Final Clean-up ---\")\n",
    "\n",
    "    # 🎯 Added Print: Show the final count of NaNs before the last drop\n",
    "    print(f\"Final EventTime NaNs before drop: {final_missing_count}\")\n",
    "\n",
    "    if final_missing_count > 0:\n",
    "        df_log.dropna(subset=[event_time_col], inplace=True)\n",
    "        \n",
    "        print(f\"Final drop: Removed {final_missing_count} residual rows.\")\n",
    "        print(f\"Rows remaining in LogFile: {len(df_log)}.\")\n",
    "    else:\n",
    "        print(\"All records now have a valid 'eventtime'. No further time-based rows were dropped. ✅\")\n",
    "\n",
    "else:\n",
    "    print(\"No further 'eventtime' NaNs found. Cleaning complete. ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50014aca",
   "metadata": {},
   "source": [
    "#### 2.3 Check for Missing Values for all columns\n",
    "Checking if the dropped values of **eventtime** is effective, and address more columns to clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6ea6a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for LogFile (Total Rows: 8682) ---\n",
      "--------------------------------------------------\n",
      "Columns with Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>creationtime</th>\n",
       "      <td>2614</td>\n",
       "      <td>30.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modifiedtime</th>\n",
       "      <td>2614</td>\n",
       "      <td>30.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mftmodifiedtime</th>\n",
       "      <td>2614</td>\n",
       "      <td>30.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accessedtime</th>\n",
       "      <td>2614</td>\n",
       "      <td>30.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullpath</th>\n",
       "      <td>988</td>\n",
       "      <td>11.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filedirectoryname</th>\n",
       "      <td>269</td>\n",
       "      <td>3.100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Missing Count  Missing Percentage\n",
       "creationtime                2614              30.110\n",
       "modifiedtime                2614              30.110\n",
       "mftmodifiedtime             2614              30.110\n",
       "accessedtime                2614              30.110\n",
       "fullpath                     988              11.380\n",
       "filedirectoryname            269               3.100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of entries\n",
    "total_rows = len(df_log)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for LogFile (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_log.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"🎉 Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a728eeb",
   "metadata": {},
   "source": [
    "##### 2.3.1 Dropping Rows with Empty Timestamps Across creationtime, modifiedtime, mftmodifiedtime, and accessedtime \n",
    "Upon observing the presented data, if there are an equal amount of empty rows across all timestamps, this could mean that they are the same rows. Any row that doesn't have any timestamps regardless if they have other information, could not provide any relevant information to us or a model. Thus, we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2efaa508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Unusable Time Records Drop Check ---\n",
      "Total rows before check: 8682\n",
      "Rows with valid 'eventtime' but NO NTFS timestamps to compare: 2614\n",
      "✅ Successfully dropped 2614 records due to insufficient timestamp evidence.\n",
      "Rows remaining in LogFile: 6068\n"
     ]
    }
   ],
   "source": [
    "# Define the columns (assuming previous cleaning steps left them as datetime objects with NaT for missing)\n",
    "event_time_col = 'eventtime'\n",
    "ntfs_timestamps = ['creationtime', 'modifiedtime', 'mftmodifiedtime', 'accessedtime']\n",
    "\n",
    "# 1. Create a mask for the rows that meet the condition\n",
    "# Condition A: eventtime is NOT missing (~df_log[event_time_col].isna())\n",
    "# Condition B: ALL four NTFS timestamps ARE missing (df_log[ntfs_timestamps].isna().all(axis=1))\n",
    "unusable_time_mask = (\n",
    "    (~df_log[event_time_col].isna()) & \n",
    "    (df_log[ntfs_timestamps].isna().all(axis=1))\n",
    ")\n",
    "\n",
    "# 2. Check and Report\n",
    "rows_to_drop = unusable_time_mask.sum()\n",
    "initial_total_rows = len(df_log)\n",
    "\n",
    "print(\"--- Unusable Time Records Drop Check ---\")\n",
    "print(f\"Total rows before check: {initial_total_rows}\")\n",
    "print(f\"Rows with valid 'eventtime' but NO NTFS timestamps to compare: {rows_to_drop}\")\n",
    "\n",
    "# 3. Conditional Drop\n",
    "if rows_to_drop > 0:\n",
    "    df_log.drop(df_log[unusable_time_mask].index, inplace=True)\n",
    "    \n",
    "    rows_remaining = len(df_log)\n",
    "    print(f\"✅ Successfully dropped {rows_to_drop} records due to insufficient timestamp evidence.\")\n",
    "    print(f\"Rows remaining in LogFile: {rows_remaining}\")\n",
    "else:\n",
    "    print(\"No records found with valid 'eventtime' but missing all four NTFS timestamps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8630156",
   "metadata": {},
   "source": [
    "#### 2.4 Check for Missing Values for all columns\n",
    "Checking if the dropped values of **creationtime**, **modifiedtime**, **mftmodifiedtime**, **accessedtime**, is effective, and address more columns to clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "386ac6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for LogFile (Total Rows: 6068) ---\n",
      "--------------------------------------------------\n",
      "Columns with Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fullpath</th>\n",
       "      <td>457</td>\n",
       "      <td>7.530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Missing Count  Missing Percentage\n",
       "fullpath            457               7.530"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of entries\n",
    "total_rows = len(df_log)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for LogFile (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_log.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"🎉 Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99aada7",
   "metadata": {},
   "source": [
    "##### 2.4.1 Dropping Empty filedirectoryname Rows \n",
    "This is because a log record that has timestamps and an event, but doesn't identify the file it applies to, is forensically vague. It tells you something happened at a certain time but not to what."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8b8ff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- File Directory Name Cleaning ---\n",
      "Total rows before cleaning: 6068\n",
      "Rows with missing 'filedirectoryname': 0\n",
      "Column 'filedirectoryname' is fully populated. No rows were dropped.\n"
     ]
    }
   ],
   "source": [
    "# Define the file identifier column\n",
    "file_name_col = 'filedirectoryname'\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "## Step 1: Check and Report Missing File Names\n",
    "# -------------------------------------------------------------\n",
    "initial_total_rows = len(df_log)\n",
    "missing_file_count = df_log[file_name_col].isna().sum()\n",
    "\n",
    "print(\"--- File Directory Name Cleaning ---\")\n",
    "print(f\"Total rows before cleaning: {initial_total_rows}\")\n",
    "print(f\"Rows with missing '{file_name_col}': {missing_file_count}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "## Step 2: Conditional Drop\n",
    "# -------------------------------------------------------------\n",
    "if missing_file_count > 0:\n",
    "    # Drop rows where the file directory name is NaN (missing the primary grouping key)\n",
    "    # We drop them in place as they are forensically useless for this analysis.\n",
    "    df_log.dropna(subset=[file_name_col], inplace=True)\n",
    "    \n",
    "    # 3. Verification\n",
    "    rows_remaining = len(df_log)\n",
    "    rows_dropped = missing_file_count\n",
    "    \n",
    "    print(f\"✅ Successfully dropped {rows_dropped} rows due to missing file identifier.\")\n",
    "    print(f\"Rows remaining in LogFile: {rows_remaining}\")\n",
    "else:\n",
    "    print(f\"Column '{file_name_col}' is fully populated. No rows were dropped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6edca0e",
   "metadata": {},
   "source": [
    "#### 2.5 Check for Missing Values for all columns\n",
    "Checking if the dropped values of **filedirectoryname** is effective, and address more columns to clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69e3ddca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for LogFile (Total Rows: 6068) ---\n",
      "--------------------------------------------------\n",
      "Columns with Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fullpath</th>\n",
       "      <td>457</td>\n",
       "      <td>7.530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Missing Count  Missing Percentage\n",
       "fullpath            457               7.530"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Check the total number of entries\n",
    "total_rows = len(df_log)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for LogFile (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_log.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"🎉 Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d21d2",
   "metadata": {},
   "source": [
    "##### 2.5.1 Imputing filedirectoryname to empty fullpath \n",
    "By filling the missing fullpath with the filedirectoryname and creating a binary flag, we maintain the record's primary timing evidence while informing the model that its location data was suspect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d292cef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FullPath Imputation and Flagging ---\n",
      "Rows with missing 'fullpath' before imputation: 457\n",
      "✅ Created binary flag column 'missingfullpathflaglsn' to mark original NaNs.\n",
      "Imputed 457 rows using 'filedirectoryname'.\n",
      "Remaining missing 'fullpath' after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Define columns\n",
    "fullpath_col = 'fullpath'\n",
    "filename_col = 'filedirectoryname'\n",
    "flag_col = 'missingfullpathflaglsn'\n",
    "\n",
    "# 1. Check initial state\n",
    "initial_missing_count = df_log[fullpath_col].isna().sum()\n",
    "\n",
    "print(\"--- FullPath Imputation and Flagging ---\")\n",
    "print(f\"Rows with missing '{fullpath_col}' before imputation: {initial_missing_count}\")\n",
    "\n",
    "if initial_missing_count > 0:\n",
    "    # 2. Create the binary flag column\n",
    "    # Flag is 1 where fullpath was originally missing, 0 otherwise. This is a valuable feature for the ML model.\n",
    "    df_log[flag_col] = df_log[fullpath_col].isna().astype(int)\n",
    "    print(f\"✅ Created binary flag column '{flag_col}' to mark original NaNs.\")\n",
    "\n",
    "    # 3. Impute missing fullpath values with the file name\n",
    "    df_log[fullpath_col] = df_log[fullpath_col].fillna(df_log[filename_col])\n",
    "\n",
    "    # 4. Report the result\n",
    "    final_missing_count = df_log[fullpath_col].isna().sum()\n",
    "    rows_imputed = initial_missing_count - final_missing_count\n",
    "    \n",
    "    print(f\"Imputed {rows_imputed} rows using '{filename_col}'.\")\n",
    "    print(f\"Remaining missing '{fullpath_col}' after imputation: {final_missing_count}\")\n",
    "\n",
    "    # 5. Final cleanup: Drop residual NaNs (where both fullpath and filename were NaN)\n",
    "    if final_missing_count > 0:\n",
    "        df_log.dropna(subset=[fullpath_col], inplace=True)\n",
    "        print(f\"Final drop: Removed {final_missing_count} rows where both fullpath and filename were NaN.\")\n",
    "        print(f\"Rows remaining in LogFile: {len(df_log)}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Column '{fullpath_col}' is fully populated. No imputation needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5269114c",
   "metadata": {},
   "source": [
    "#### 2.6 Check for Missing Values for all columns\n",
    "Checking if the values of **fullpath** is effective, and address more columns to clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89274253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for LogFile (Total Rows: 6068) ---\n",
      "--------------------------------------------------\n",
      "🎉 Congratulations! No missing values found in any column.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Check the total number of entries\n",
    "total_rows = len(df_log)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for LogFile (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_log.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"🎉 Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2934a092",
   "metadata": {},
   "source": [
    "### 3. Present the cleaned LogFile table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75bf5d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LogFile Inspection ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsn</th>\n",
       "      <th>eventtime</th>\n",
       "      <th>event</th>\n",
       "      <th>filedirectoryname</th>\n",
       "      <th>fullpath</th>\n",
       "      <th>creationtime</th>\n",
       "      <th>modifiedtime</th>\n",
       "      <th>mftmodifiedtime</th>\n",
       "      <th>accessedtime</th>\n",
       "      <th>redo</th>\n",
       "      <th>targetvcn</th>\n",
       "      <th>clusterindex</th>\n",
       "      <th>missingfullpathflaglsn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006785113</td>\n",
       "      <td>12/25/23 22:19:43</td>\n",
       "      <td>File Deletion</td>\n",
       "      <td>UDB-User23847576+RemoteGraph.sql-journal</td>\n",
       "      <td>\\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...</td>\n",
       "      <td>12/25/23 22:19:43</td>\n",
       "      <td>12/25/23 22:19:48</td>\n",
       "      <td>12/25/23 22:19:48</td>\n",
       "      <td>12/25/23 22:19:48</td>\n",
       "      <td>Deallocate File Record Segment</td>\n",
       "      <td>0x2FB7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10006785298</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>File Creation</td>\n",
       "      <td>UDB-User23847576+LocalStorage.sql-journal</td>\n",
       "      <td>\\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>Initialize File Record Segment</td>\n",
       "      <td>0x2FB7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10006786545</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>File Deletion</td>\n",
       "      <td>UDB-User23847576+LocalStorage.sql-journal</td>\n",
       "      <td>\\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>Deallocate File Record Segment</td>\n",
       "      <td>0x2FB7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10006786739</td>\n",
       "      <td>12/25/23 22:19:43</td>\n",
       "      <td>File Creation</td>\n",
       "      <td>UDB-User23847576+RemoteGraph.sql-journal</td>\n",
       "      <td>\\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...</td>\n",
       "      <td>12/25/23 22:19:43</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>Initialize File Record Segment</td>\n",
       "      <td>0x2FB7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10006787986</td>\n",
       "      <td>12/25/23 22:19:43</td>\n",
       "      <td>File Deletion</td>\n",
       "      <td>UDB-User23847576+RemoteGraph.sql-journal</td>\n",
       "      <td>\\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...</td>\n",
       "      <td>12/25/23 22:19:43</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>12/25/23 22:19:50</td>\n",
       "      <td>Deallocate File Record Segment</td>\n",
       "      <td>0x2FB7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lsn          eventtime          event                          filedirectoryname                                           fullpath       creationtime       modifiedtime    mftmodifiedtime       accessedtime                            redo targetvcn  clusterindex  missingfullpathflaglsn\n",
       "0  10006785113  12/25/23 22:19:43  File Deletion   UDB-User23847576+RemoteGraph.sql-journal  \\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...  12/25/23 22:19:43  12/25/23 22:19:48  12/25/23 22:19:48  12/25/23 22:19:48  Deallocate File Record Segment    0x2FB7             6                       0\n",
       "1  10006785298  12/25/23 22:19:50  File Creation  UDB-User23847576+LocalStorage.sql-journal  \\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...  12/25/23 22:19:50  12/25/23 22:19:50  12/25/23 22:19:50  12/25/23 22:19:50  Initialize File Record Segment    0x2FB7             6                       0\n",
       "4  10006786545  12/25/23 22:19:50  File Deletion  UDB-User23847576+LocalStorage.sql-journal  \\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...  12/25/23 22:19:50  12/25/23 22:19:50  12/25/23 22:19:50  12/25/23 22:19:50  Deallocate File Record Segment    0x2FB7             6                       0\n",
       "5  10006786739  12/25/23 22:19:43  File Creation   UDB-User23847576+RemoteGraph.sql-journal  \\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...  12/25/23 22:19:43  12/25/23 22:19:50  12/25/23 22:19:50  12/25/23 22:19:50  Initialize File Record Segment    0x2FB7             6                       0\n",
       "8  10006787986  12/25/23 22:19:43  File Deletion   UDB-User23847576+RemoteGraph.sql-journal  \\Users\\blueangel\\AppData\\Roaming\\Evernote\\cond...  12/25/23 22:19:43  12/25/23 22:19:50  12/25/23 22:19:50  12/25/23 22:19:50  Deallocate File Record Segment    0x2FB7             6                       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 6068 entries, 0 to 25686\n",
      "Columns: 13 entries, lsn to missingfullpathflaglsn\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 4.5 MB\n",
      "LogFile data loaded successfully. Shape: (6068, 13)\n"
     ]
    }
   ],
   "source": [
    "# Check LogFile structure\n",
    "print(\"\\n--- LogFile Inspection ---\")\n",
    "display(df_log.head())\n",
    "df_log.info(verbose=False, memory_usage='deep')\n",
    "print(f\"LogFile data loaded successfully. Shape: {df_log.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2259700e",
   "metadata": {},
   "source": [
    "### 4. Exporting the Cleaned LogFile to data/processed/phase 1 - cleaning folder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "230669cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LogFile table successfully exported to: data/processed/phase 1 - cleaned/09-PE-LogFile-Cleaned.csv and is now ready for Phase 2 - Data Merging\n"
     ]
    }
   ],
   "source": [
    "# Observe the format [Sub-Folder Number]-PE-LogFile-Cleaned.csv for consistency \n",
    "# Example: 09-PE-LogFile-Cleaned.csv\n",
    "\n",
    "# Define the target folder path and filename\n",
    "folder_path = 'data/processed/phase 1 - cleaned'\n",
    "filename = '09-PE-LogFile-Cleaned.csv'\n",
    "full_output_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Define the columns that need formatting\n",
    "time_cols = ['eventtime', 'creationtime', 'modifiedtime', 'mftmodifiedtime', 'accessedtime']\n",
    "\n",
    "# 1. Create a COPY of the DataFrame for string formatting\n",
    "df_export = df_log.copy()\n",
    "\n",
    "# 2. Convert all time columns to the desired string format\n",
    "for col in time_cols:\n",
    "    if col in df_export.columns:\n",
    "        # 🎯 EFFICIENT FIX: Safely apply the string format only if the column is currently a datetime dtype.\n",
    "        # This avoids the slow re-parsing and the UserWarning.\n",
    "        if pd.api.types.is_datetime64_any_dtype(df_export[col]):\n",
    "            df_export[col] = df_export[col].dt.strftime('%m/%d/%Y %H:%M:%S')\n",
    "        # ELSE: If it's a string/object type (like NaT converted to a string), we leave it alone.\n",
    "            \n",
    "# 3. Ensure the folder exists\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# 4. Export the formatted DataFrame to CSV with UTF-8 encoding\n",
    "df_export.to_csv(full_output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"✅ LogFile table successfully exported to: {full_output_path} and is now ready for Phase 2 - Data Merging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4682598",
   "metadata": {},
   "source": [
    "## UsnJrnl Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eceda3",
   "metadata": {},
   "source": [
    "### 0. Presenting Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d17f1fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- UsnJrnl Initial Inspection ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp(UTC+8)</th>\n",
       "      <th>USN</th>\n",
       "      <th>File/Directory Name</th>\n",
       "      <th>FullPath</th>\n",
       "      <th>EventInfo</th>\n",
       "      <th>SourceInfo</th>\n",
       "      <th>FileAttribute</th>\n",
       "      <th>Carving Flag</th>\n",
       "      <th>FileReferenceNumber</th>\n",
       "      <th>ParentFileReferenceNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677721600</td>\n",
       "      <td>amd64_windows-shield-provider.resources_31bf38...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Directory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x000100000007BDEC</td>\n",
       "      <td>0x000300000002CC20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677721848</td>\n",
       "      <td>amd64_windows-shield-provider.resources_31bf38...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x0001000000073F99</td>\n",
       "      <td>0x000300000002CC20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677722120</td>\n",
       "      <td>securityhealthagent.dll.mui</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x000100000007BE07</td>\n",
       "      <td>0x000100000007BE06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677722240</td>\n",
       "      <td>windowsdefendersecuritycenter.adml</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x000100000007D7AA</td>\n",
       "      <td>0x000100000007BE06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677722368</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Directory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x000100000007BE06</td>\n",
       "      <td>0x000100000007BE05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TimeStamp(UTC+8)         USN                                File/Directory Name FullPath                   EventInfo SourceInfo FileAttribute  Carving Flag FileReferenceNumber ParentFileReferenceNumber\n",
       "0  12/25/23 16:47:05  1677721600  amd64_windows-shield-provider.resources_31bf38...      NaN  File_Closed / File_Deleted     Normal     Directory           NaN  0x000100000007BDEC        0x000300000002CC20\n",
       "1  12/25/23 16:47:05  1677721848  amd64_windows-shield-provider.resources_31bf38...      NaN  File_Closed / File_Deleted     Normal        Normal           NaN  0x0001000000073F99        0x000300000002CC20\n",
       "2  12/25/23 16:47:05  1677722120                        securityhealthagent.dll.mui      NaN  File_Closed / File_Deleted     Normal        Normal           NaN  0x000100000007BE07        0x000100000007BE06\n",
       "3  12/25/23 16:47:05  1677722240                 windowsdefendersecuritycenter.adml      NaN  File_Closed / File_Deleted     Normal        Normal           NaN  0x000100000007D7AA        0x000100000007BE06\n",
       "4  12/25/23 16:47:05  1677722368                                                  f      NaN  File_Closed / File_Deleted     Normal     Directory           NaN  0x000100000007BE06        0x000100000007BE05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249559 entries, 0 to 249558\n",
      "Columns: 10 entries, TimeStamp(UTC+8) to ParentFileReferenceNumber\n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 143.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Check UsnJrnl structure\n",
    "print(\"\\n--- UsnJrnl Initial Inspection ---\")\n",
    "display(df_usn.head())\n",
    "df_usn.info(verbose=False, memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0903ecd",
   "metadata": {},
   "source": [
    "### 1. Standardize Column Names\n",
    "First, we must standardize the column names for uniformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "802e9818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New UsnJrnl Columns: ['timestamp', 'usn', 'filedirectoryname', 'fullpath', 'eventinfo', 'sourceinfo', 'fileattribute', 'carvingflag', 'filereferencenumber', 'parentfilereferencenumber']\n"
     ]
    }
   ],
   "source": [
    "# 1. Standardize column names: lowercase, remove special characters/parentheses, replace spaces with underscores.\n",
    "df_usn.columns = (\n",
    "    df_usn.columns\n",
    "    .str.lower()\n",
    "    .str.replace(r'\\(.*?\\)', '', regex=True) # Remove anything in parentheses (like '(UTC+8)')\n",
    "    .str.replace('[^a-z0-9_]', '', regex=True) # Remove other non-alphanumeric chars (like slashes)\n",
    "    .str.replace(' ', '_', regex=False)\n",
    "    .str.replace('__', '_', regex=False) # Handle double underscores if they result\n",
    "    .str.strip('_') # Remove leading/trailing underscores\n",
    ")\n",
    "\n",
    "# Display the new, clean column names\n",
    "print(\"New UsnJrnl Columns:\", df_usn.columns.tolist())\n",
    "\n",
    "# Rename specific columns for clarity if needed (e.g., 'eventdetail' is a good name already)\n",
    "# If your column is now just 'eventdetail', you are good to go.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1847e8",
   "metadata": {},
   "source": [
    "### 2. Addressing Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e02fb",
   "metadata": {},
   "source": [
    "#### 2.1 Check for Missing Values for all columns\n",
    "Now we can accurately check for missing values in all columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0c39460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for UsnJrnl (Total Rows: 249559) ---\n",
      "--------------------------------------------------\n",
      "Columns with Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>carvingflag</th>\n",
       "      <td>249559</td>\n",
       "      <td>100.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullpath</th>\n",
       "      <td>114161</td>\n",
       "      <td>45.750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Missing Count  Missing Percentage\n",
       "carvingflag         249559             100.000\n",
       "fullpath            114161              45.750"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of entries\n",
    "total_rows = len(df_usn)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for UsnJrnl (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_usn.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"🎉 Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf7f52e",
   "metadata": {},
   "source": [
    "##### 2.1.1 Dropping carvingflag column \n",
    "Since **carvingflag** is 100% missing, the column provides absolutely no data or analytical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8752d6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dropped 'carvingflag' column due to 100% missing values.\n"
     ]
    }
   ],
   "source": [
    "# Drop the carvingflag column as it is entirely missing (100%)\n",
    "if 'carvingflag' in df_usn.columns:\n",
    "    df_usn.drop(columns=['carvingflag'], inplace=True)\n",
    "    print(\"✅ Dropped 'carvingflag' column due to 100% missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57969078",
   "metadata": {},
   "source": [
    "#### 2.2 Check for Missing Values for all columns\n",
    "Checking if the dropped column of **carvingflag** is effective, and address more columns to clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e47ca6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for UsnJrnl (Total Rows: 249559) ---\n",
      "--------------------------------------------------\n",
      "Columns with Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fullpath</th>\n",
       "      <td>114161</td>\n",
       "      <td>45.750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Missing Count  Missing Percentage\n",
       "fullpath         114161              45.750"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of entries\n",
    "total_rows = len(df_usn)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for UsnJrnl (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_usn.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"🎉 Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c2a9e6",
   "metadata": {},
   "source": [
    "##### 2.2.1 Addressing missing fullpath values \n",
    "The fullpath column is essential for grouping events and providing location context. Since the missing percentage is manageable and this column is critical for feature engineering, we should impute it. Impute the missing fullpath with filedirectoryname and create a flag to mark where the original path was missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e15782e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FullPath Imputation ---\n",
      "✅ Created binary flag column 'missingfullpathflagusn'.\n",
      "Imputed 114161 rows using 'filedirectoryname'.\n",
      "\n",
      "UsnJrnl Cleaning Complete. Final Rows: 249559\n"
     ]
    }
   ],
   "source": [
    "# 1. Define columns\n",
    "filedirectoryname_col = 'filedirectoryname'\n",
    "fullpath_col = 'fullpath'\n",
    "flag_col = 'missingfullpathflagusn'\n",
    "label_col = 'df.usn'\n",
    "\n",
    "# --- Step 1: Drop carvingflag (100% Missing) ---\n",
    "if 'carvingflag' in df_usn.columns:\n",
    "    df_usn.drop(columns=['carvingflag'], inplace=True)\n",
    "    print(\"✅ Dropped 'carvingflag' column due to 100% missing values.\")\n",
    "\n",
    "# --- Step 2: FullPath Imputation and Flagging (FIXED) ---\n",
    "initial_missing_count = df_usn[fullpath_col].isna().sum()\n",
    "\n",
    "if initial_missing_count > 0 and filedirectoryname_col in df_usn.columns:\n",
    "    \n",
    "    print(f\"\\n--- FullPath Imputation ---\")\n",
    "    \n",
    "    # 1. Create a binary flag to mark where the fullpath was originally missing\n",
    "    df_usn[flag_col] = df_usn[fullpath_col].isna().astype(int)\n",
    "    print(f\"✅ Created binary flag column '{flag_col}'.\")\n",
    "    \n",
    "    # 2. Impute missing fullpath values with the filedirectoryname (SAFE ASSIGNMENT)\n",
    "    df_usn[fullpath_col] = df_usn[fullpath_col].fillna(df_usn[filedirectoryname_col]) # ⬅️ Put the fixed line HERE\n",
    "\n",
    "    rows_imputed = initial_missing_count - df_usn[fullpath_col].isna().sum()\n",
    "    \n",
    "    print(f\"Imputed {rows_imputed} rows using '{filedirectoryname_col}'.\")\n",
    "\n",
    "# --- Step 3: Final Cleanup (Drop residual NaNs in Critical Columns) ---\n",
    "\n",
    "# Drop rows where 'fullpath' is still missing (meaning filedirectoryname was also missing)\n",
    "rows_to_drop_fullpath = df_usn[fullpath_col].isna().sum()\n",
    "if rows_to_drop_fullpath > 0:\n",
    "    df_usn.dropna(subset=[fullpath_col], inplace=True)\n",
    "    print(f\"Final drop: Removed {rows_to_drop_fullpath} rows where both fullpath and filedirectoryname were missing.\")\n",
    "\n",
    "# Check/Drop rows where the LABEL is missing (critical for ML)\n",
    "if label_col in df_usn.columns:\n",
    "    rows_to_drop_label = df_usn[label_col].isna().sum()\n",
    "    if rows_to_drop_label > 0:\n",
    "        df_usn.dropna(subset=[label_col], inplace=True)\n",
    "        print(f\"Final drop: Removed {rows_to_drop_label} rows due to missing ML label ('{label_col}').\")\n",
    "\n",
    "print(f\"\\nUsnJrnl Cleaning Complete. Final Rows: {len(df_usn)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82a5f52",
   "metadata": {},
   "source": [
    "#### 2.3 Check for Missing Values for all columns \n",
    "Checking if the imputation of  **fullpath** is effective, and if there are more columns need to be addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7df392ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for UsnJrnl (Total Rows: 249559) ---\n",
      "--------------------------------------------------\n",
      "🎉 Congratulations! No missing values found in any column.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of entries\n",
    "total_rows = len(df_usn)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for UsnJrnl (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_usn.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"🎉 Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc4c056",
   "metadata": {},
   "source": [
    "### 3. Present the cleaned UsnJrnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c551a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- UsnJrnl  Inspection ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>usn</th>\n",
       "      <th>filedirectoryname</th>\n",
       "      <th>fullpath</th>\n",
       "      <th>eventinfo</th>\n",
       "      <th>sourceinfo</th>\n",
       "      <th>fileattribute</th>\n",
       "      <th>filereferencenumber</th>\n",
       "      <th>parentfilereferencenumber</th>\n",
       "      <th>missingfullpathflagusn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677721600</td>\n",
       "      <td>amd64_windows-shield-provider.resources_31bf38...</td>\n",
       "      <td>amd64_windows-shield-provider.resources_31bf38...</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Directory</td>\n",
       "      <td>0x000100000007BDEC</td>\n",
       "      <td>0x000300000002CC20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677721848</td>\n",
       "      <td>amd64_windows-shield-provider.resources_31bf38...</td>\n",
       "      <td>amd64_windows-shield-provider.resources_31bf38...</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0x0001000000073F99</td>\n",
       "      <td>0x000300000002CC20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677722120</td>\n",
       "      <td>securityhealthagent.dll.mui</td>\n",
       "      <td>securityhealthagent.dll.mui</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0x000100000007BE07</td>\n",
       "      <td>0x000100000007BE06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677722240</td>\n",
       "      <td>windowsdefendersecuritycenter.adml</td>\n",
       "      <td>windowsdefendersecuritycenter.adml</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0x000100000007D7AA</td>\n",
       "      <td>0x000100000007BE06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677722368</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Directory</td>\n",
       "      <td>0x000100000007BE06</td>\n",
       "      <td>0x000100000007BE05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           timestamp         usn                                  filedirectoryname                                           fullpath                   eventinfo sourceinfo fileattribute filereferencenumber parentfilereferencenumber  missingfullpathflagusn\n",
       "0  12/25/23 16:47:05  1677721600  amd64_windows-shield-provider.resources_31bf38...  amd64_windows-shield-provider.resources_31bf38...  File_Closed / File_Deleted     Normal     Directory  0x000100000007BDEC        0x000300000002CC20                       1\n",
       "1  12/25/23 16:47:05  1677721848  amd64_windows-shield-provider.resources_31bf38...  amd64_windows-shield-provider.resources_31bf38...  File_Closed / File_Deleted     Normal        Normal  0x0001000000073F99        0x000300000002CC20                       1\n",
       "2  12/25/23 16:47:05  1677722120                        securityhealthagent.dll.mui                        securityhealthagent.dll.mui  File_Closed / File_Deleted     Normal        Normal  0x000100000007BE07        0x000100000007BE06                       1\n",
       "3  12/25/23 16:47:05  1677722240                 windowsdefendersecuritycenter.adml                 windowsdefendersecuritycenter.adml  File_Closed / File_Deleted     Normal        Normal  0x000100000007D7AA        0x000100000007BE06                       1\n",
       "4  12/25/23 16:47:05  1677722368                                                  f                                                  f  File_Closed / File_Deleted     Normal     Directory  0x000100000007BE06        0x000100000007BE05                       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249559 entries, 0 to 249558\n",
      "Columns: 10 entries, timestamp to missingfullpathflagusn\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 150.9 MB\n",
      "UsnJrnl data loaded successfully. Shape: (6068, 13)\n"
     ]
    }
   ],
   "source": [
    "# Check UsnJrnl structure\n",
    "print(\"\\n--- UsnJrnl  Inspection ---\")\n",
    "display(df_usn.head())\n",
    "df_usn.info(verbose=False, memory_usage='deep')\n",
    "print(f\"UsnJrnl data loaded successfully. Shape: {df_log.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bf3906",
   "metadata": {},
   "source": [
    "### 4. Addressing sourceinfo\n",
    "From the presented table, the **sourceinfo** column seems to contain only one instance: \"Normal\". Should this be the case, we can drop this column as it has no predicitive power. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a151b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Unique Values Check for 'sourceinfo' ---\n",
      "Total unique values (including NaN): 1\n",
      "\n",
      "Value Counts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source Value</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Normal</td>\n",
       "      <td>249559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Source Value   Count\n",
       "0       Normal  249559"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ CONFIRMED: The column contains only 'Normal'.\n",
      "DECISION: This is a zero-variance feature and should be dropped.\n"
     ]
    }
   ],
   "source": [
    "source_col = 'sourceinfo'\n",
    "\n",
    "if source_col in df_usn.columns:\n",
    "    \n",
    "    print(f\"--- Unique Values Check for '{source_col}' ---\")\n",
    "    \n",
    "    # Get the value counts and convert the resulting Series to a DataFrame for clean presentation\n",
    "    value_counts_df = df_usn[source_col].value_counts(dropna=True).reset_index()\n",
    "    value_counts_df.columns = ['Source Value', 'Count']\n",
    "    \n",
    "    # Handle the count of missing values (NaN) separately\n",
    "    nan_count = df_usn[source_col].isna().sum()\n",
    "    \n",
    "    # Calculate the total number of unique values (including NaN)\n",
    "    unique_count = df_usn[source_col].nunique(dropna=False)\n",
    "\n",
    "    print(f\"Total unique values (including NaN): {unique_count}\")\n",
    "    print(\"\\nValue Counts:\")\n",
    "    \n",
    "    # Display the table\n",
    "    from IPython.display import display\n",
    "    display(value_counts_df)\n",
    "    \n",
    "    if nan_count > 0:\n",
    "        print(f\"Missing Values (NaN) Count: {nan_count}\")\n",
    "\n",
    "    # --- Confirmation/Decision Check ---\n",
    "    # Case 1: Only 'Normal' and potentially NaNs exist\n",
    "    if unique_count <= 2 and (unique_count == 1 or (unique_count == 2 and nan_count > 0)):\n",
    "        print(\"\\n✅ CONFIRMED: The column contains only 'Normal'.\")\n",
    "        print(\"DECISION: This is a zero-variance feature and should be dropped.\")\n",
    "    else:\n",
    "        print(\"\\n🛑 WARNING: The column contains more than one substantive unique value and should be retained for feature engineering.\")\n",
    "        \n",
    "else:\n",
    "    print(f\"Column '{source_col}' not found in df_usn.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10476352",
   "metadata": {},
   "source": [
    "#### 4.1 Dropping sourceinfo column\n",
    "Upon confirmation that there is only one instance to the column, we can now drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "debed20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully dropped the 'sourceinfo' column due to zero variance ('Normal' only).\n",
      "Columns remaining: ['timestamp', 'usn', 'filedirectoryname', 'fullpath', 'eventinfo', 'fileattribute', 'filereferencenumber', 'parentfilereferencenumber', 'missingfullpathflagusn']\n"
     ]
    }
   ],
   "source": [
    "# Define the column to be dropped\n",
    "source_col = 'sourceinfo'\n",
    "\n",
    "if source_col in df_usn.columns:\n",
    "    # Drop the 'sourceinfo' column permanently\n",
    "    df_usn.drop(columns=[source_col], inplace=True)\n",
    "    \n",
    "    print(f\"✅ Successfully dropped the '{source_col}' column due to zero variance ('Normal' only).\")\n",
    "    print(f\"Columns remaining: {list(df_usn.columns)}\")\n",
    "else:\n",
    "    print(f\"Column '{source_col}' was already dropped or not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab36d28",
   "metadata": {},
   "source": [
    "### 5. Present the cleaned UsnJrnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3b660611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- UsnJrnl  Inspection ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>usn</th>\n",
       "      <th>filedirectoryname</th>\n",
       "      <th>fullpath</th>\n",
       "      <th>eventinfo</th>\n",
       "      <th>fileattribute</th>\n",
       "      <th>filereferencenumber</th>\n",
       "      <th>parentfilereferencenumber</th>\n",
       "      <th>missingfullpathflagusn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677721600</td>\n",
       "      <td>amd64_windows-shield-provider.resources_31bf38...</td>\n",
       "      <td>amd64_windows-shield-provider.resources_31bf38...</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Directory</td>\n",
       "      <td>0x000100000007BDEC</td>\n",
       "      <td>0x000300000002CC20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677721848</td>\n",
       "      <td>amd64_windows-shield-provider.resources_31bf38...</td>\n",
       "      <td>amd64_windows-shield-provider.resources_31bf38...</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0x0001000000073F99</td>\n",
       "      <td>0x000300000002CC20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677722120</td>\n",
       "      <td>securityhealthagent.dll.mui</td>\n",
       "      <td>securityhealthagent.dll.mui</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0x000100000007BE07</td>\n",
       "      <td>0x000100000007BE06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677722240</td>\n",
       "      <td>windowsdefendersecuritycenter.adml</td>\n",
       "      <td>windowsdefendersecuritycenter.adml</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0x000100000007D7AA</td>\n",
       "      <td>0x000100000007BE06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/25/23 16:47:05</td>\n",
       "      <td>1677722368</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>File_Closed / File_Deleted</td>\n",
       "      <td>Directory</td>\n",
       "      <td>0x000100000007BE06</td>\n",
       "      <td>0x000100000007BE05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           timestamp         usn                                  filedirectoryname                                           fullpath                   eventinfo fileattribute filereferencenumber parentfilereferencenumber  missingfullpathflagusn\n",
       "0  12/25/23 16:47:05  1677721600  amd64_windows-shield-provider.resources_31bf38...  amd64_windows-shield-provider.resources_31bf38...  File_Closed / File_Deleted     Directory  0x000100000007BDEC        0x000300000002CC20                       1\n",
       "1  12/25/23 16:47:05  1677721848  amd64_windows-shield-provider.resources_31bf38...  amd64_windows-shield-provider.resources_31bf38...  File_Closed / File_Deleted        Normal  0x0001000000073F99        0x000300000002CC20                       1\n",
       "2  12/25/23 16:47:05  1677722120                        securityhealthagent.dll.mui                        securityhealthagent.dll.mui  File_Closed / File_Deleted        Normal  0x000100000007BE07        0x000100000007BE06                       1\n",
       "3  12/25/23 16:47:05  1677722240                 windowsdefendersecuritycenter.adml                 windowsdefendersecuritycenter.adml  File_Closed / File_Deleted        Normal  0x000100000007D7AA        0x000100000007BE06                       1\n",
       "4  12/25/23 16:47:05  1677722368                                                  f                                                  f  File_Closed / File_Deleted     Directory  0x000100000007BE06        0x000100000007BE05                       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 249559 entries, 0 to 249558\n",
      "Columns: 9 entries, timestamp to missingfullpathflagusn\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 137.8 MB\n",
      "UsnJrnl data loaded successfully. Shape: (249559, 9)\n"
     ]
    }
   ],
   "source": [
    "# Check UsnJrnl structure\n",
    "print(\"\\n--- UsnJrnl  Inspection ---\")\n",
    "display(df_usn.head())\n",
    "df_usn.info(verbose=False, memory_usage='deep')\n",
    "print(f\"UsnJrnl data loaded successfully. Shape: {df_usn.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a79db31",
   "metadata": {},
   "source": [
    "### 6. Export the Cleaned UsnJrnl to data/processed/phase 1 - cleaning folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b0fef0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ USNJRNL table successfully exported to: data/processed/phase 1 - cleaned/09-PE-UsnJrnl-Cleaned.csv and is now ready for Phase 2 - Data Merging\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Observe the format [Sub-Folder Number]-PE-UsnJrnl-Cleaned.csv for consistency\n",
    "# Example: 09-PE-LogFile-Cleaned.csv\n",
    "\n",
    "# Define the target folder path and filename\n",
    "folder_path = 'data/processed/phase 1 - cleaned'\n",
    "filename = '09-PE-UsnJrnl-Cleaned.csv' \n",
    "full_output_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Define the columns that need formatting\n",
    "time_cols = ['timestamp'] \n",
    "\n",
    "# 1. Create a COPY of the DataFrame for string formatting\n",
    "df_export = df_usn.copy() \n",
    "\n",
    "# 2. Convert all time columns to the desired string format\n",
    "for col in time_cols:\n",
    "    if col in df_export.columns:\n",
    "        # Safely apply the string format only if the column is currently a datetime dtype.\n",
    "        if pd.api.types.is_datetime64_any_dtype(df_export[col]):\n",
    "            df_export[col] = df_export[col].dt.strftime('%m/%d/%Y %H:%M:%S')\n",
    "        # Otherwise, the column is already a string/object (like a clean NaT string), so we leave it alone.\n",
    "\n",
    "# 3. Ensure the folder exists\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# 4. Export the formatted DataFrame to CSV with UTF-8 encoding\n",
    "df_export.to_csv(full_output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"✅ USNJRNL table successfully exported to: {full_output_path} and is now ready for Phase 2 - Data Merging\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
