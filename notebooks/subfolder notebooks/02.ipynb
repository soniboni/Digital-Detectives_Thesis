{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbbe36bb",
   "metadata": {},
   "source": [
    "## 1. File Paths and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e780cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Phase 1: Data Labeling...\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# --- 1. File Paths and Setup ---\n",
    "LOGFILE_PATH = 'data/raw/02-PE-LogFile.csv'\n",
    "USNJRNL_PATH = 'data/raw/02-PE-UsnJrnl.csv'\n",
    "SUSPICIOUS_PATH = 'data/raw/suspicious/02-PE-Suspicious.csv'\n",
    "OUTPUT_DIR = 'data/processed/Phase 1 - Data Labeling'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Starting Phase 1: Data Labeling...\")\n",
    "print(\"-\" * 40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc5bd82",
   "metadata": {},
   "source": [
    "## 2. Load Datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df122910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully standardized column names to lowercase.\n",
      "Loaded LogFile with 14783 records.\n",
      "Loaded UsnJrnl with 247386 records.\n",
      "Loaded Suspicious with 3 records.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Load Datasets and Standardize Columns ---\n",
    "try:\n",
    "    df_logfile = pd.read_csv(LOGFILE_PATH, low_memory=False)\n",
    "    df_usnjrnl = pd.read_csv(USNJRNL_PATH, low_memory=False)\n",
    "    df_suspicious = pd.read_csv(SUSPICIOUS_PATH, low_memory=False)\n",
    "\n",
    "    # --- NEW: Standardize all column names to lowercase ---\n",
    "    df_logfile.columns = df_logfile.columns.str.lower()\n",
    "    df_usnjrnl.columns = df_usnjrnl.columns.str.lower()\n",
    "    df_suspicious.columns = df_suspicious.columns.str.lower()\n",
    "    \n",
    "    # Check for the key columns now in lowercase (lsn and usn)\n",
    "    if 'lsn' not in df_logfile.columns:\n",
    "        print(\"Error: 'lsn' column not found in LogFile even after converting to lowercase. Please check the original column name.\")\n",
    "        # Print actual columns for debugging if the error persists\n",
    "        # print(\"LogFile Columns:\", df_logfile.columns.tolist()) \n",
    "        exit()\n",
    "        \n",
    "    if 'usn' not in df_usnjrnl.columns:\n",
    "        print(\"Error: 'usn' column not found in UsnJrnl even after converting to lowercase. Please check the original column name.\")\n",
    "        exit()\n",
    "        \n",
    "    print(\"Successfully standardized column names to lowercase.\")\n",
    "    print(f\"Loaded LogFile with {len(df_logfile)} records.\")\n",
    "    print(f\"Loaded UsnJrnl with {len(df_usnjrnl)} records.\")\n",
    "    print(f\"Loaded Suspicious with {len(df_suspicious)} records.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Required file not found. Check file paths: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Clean up column names for joining: 'lsn/usn' is now 'lsn/usn' (lowercase)\n",
    "df_suspicious.rename(columns={'lsn/usn': 'id'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66a8afc",
   "metadata": {},
   "source": [
    "## 3. Initialize Label Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dd52d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized new label columns to 0.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Initialize Label Columns ---\n",
    "\n",
    "# Initialize new columns to 0 in both DataFrames\n",
    "df_logfile['is_timestomped'] = 0\n",
    "df_logfile['is_suspicious_execution'] = 0\n",
    "\n",
    "df_usnjrnl['is_timestomped'] = 0\n",
    "df_usnjrnl['is_suspicious_execution'] = 0\n",
    "\n",
    "print(\"Initialized new label columns to 0.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55425a8c",
   "metadata": {},
   "source": [
    "## 4. Process and Apply Labels from Suspicious Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bc36ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogFile: Labeled 1 unique IDs as is_timestomped (lsn match).\n",
      "LogFile: Labeled 1 unique IDs as is_suspicious_execution (lsn match).\n",
      "UsnJrnl: Labeled 0 unique IDs as is_timestomped (usn match).\n",
      "UsnJrnl: Labeled 1 unique IDs as is_suspicious_execution (usn match).\n",
      "\n",
      "Total unique suspicious IDs found and labeled in the logs: 3\n",
      "Total entries in suspicious CSV: 3\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Process and Apply Labels from Suspicious Data ---\n",
    "\n",
    "# Split suspicious findings by source (which is now lowercase)\n",
    "suspicious_logfile = df_suspicious[df_suspicious['source'] == 'logfile'].copy()\n",
    "suspicious_usnjrnl = df_suspicious[df_suspicious['source'] == 'usnjrnl'].copy()\n",
    "\n",
    "# A helper function to apply the labels\n",
    "def apply_labels(df, suspicious_df, id_col):\n",
    "    # Standardize column for category checks\n",
    "    df_temp = suspicious_df.copy()\n",
    "\n",
    "    # --- Timestomping Label ---\n",
    "    # Filter suspicious records that are categorized as Timestamp Manipulation\n",
    "    ts_ids = df_temp[df_temp['category'] == 'Timestamp Manipulation']['id'].unique()\n",
    "    \n",
    "    # Check if any IDs were found\n",
    "    if len(ts_ids) > 0:\n",
    "        # Match the IDs and set the label to 1\n",
    "        # This line now safely uses the lowercase id_col ('lsn' or 'usn') \n",
    "        # because the main DataFrame columns were standardized above.\n",
    "        df.loc[df[id_col].isin(ts_ids), 'is_timestomped'] = 1\n",
    "    \n",
    "    # --- Suspicious Execution Label ---\n",
    "    # Filter suspicious records that are categorized as Execution of Suspicious Programs\n",
    "    exec_ids = df_temp[df_temp['category'] == 'Execution of Suspicious Programs']['id'].unique()\n",
    "    \n",
    "    if len(exec_ids) > 0:\n",
    "        # Match the IDs and set the label to 1\n",
    "        df.loc[df[id_col].isin(exec_ids), 'is_suspicious_execution'] = 1\n",
    "        \n",
    "    return len(ts_ids), len(exec_ids)\n",
    "\n",
    "# --- Apply labels to LogFile ---\n",
    "# The ID column in df_logfile is now guaranteed to be 'lsn' (lowercase)\n",
    "ts_log_count, exec_log_count = apply_labels(df_logfile, suspicious_logfile, 'lsn')\n",
    "print(f\"LogFile: Labeled {ts_log_count} unique IDs as is_timestomped (lsn match).\")\n",
    "print(f\"LogFile: Labeled {exec_log_count} unique IDs as is_suspicious_execution (lsn match).\")\n",
    "\n",
    "# --- Apply labels to UsnJrnl ---\n",
    "# The ID column in df_usnjrnl is now guaranteed to be 'usn' (lowercase)\n",
    "ts_usn_count, exec_usn_count = apply_labels(df_usnjrnl, suspicious_usnjrnl, 'usn')\n",
    "print(f\"UsnJrnl: Labeled {ts_usn_count} unique IDs as is_timestomped (usn match).\")\n",
    "print(f\"UsnJrnl: Labeled {exec_usn_count} unique IDs as is_suspicious_execution (usn match).\")\n",
    "\n",
    "# --- Verification Check ---\n",
    "total_labeled_unique_ids = (ts_log_count + exec_log_count) + (ts_usn_count + exec_usn_count)\n",
    "print(f\"\\nTotal unique suspicious IDs found and labeled in the logs: {total_labeled_unique_ids}\")\n",
    "print(f\"Total entries in suspicious CSV: {len(df_suspicious)}\")\n",
    "if total_labeled_unique_ids < len(df_suspicious):\n",
    "    print(f\"NOTE: Labeled unique IDs ({total_labeled_unique_ids}) is less than total entries in suspicious CSV ({len(df_suspicious)}).\")\n",
    "    print(\"This is expected if the suspicious CSV has duplicate IDs or one ID is flagged for BOTH timestomping and execution.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79bbf77",
   "metadata": {},
   "source": [
    "## 5. Output Labeled Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "110f79b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogFile saved to: data/processed/Phase 1 - Data Labeling/02-PE-LogFile_labeled.csv\n",
      "UsnJrnl saved to: data/processed/Phase 1 - Data Labeling/02-PE-UsnJrnl_labeled.csv\n",
      "----------------------------------------\n",
      "Phase 1: Data Labeling Complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 5. Output Labeled Datasets ---\n",
    "logfile_output_path = os.path.join(OUTPUT_DIR, '02-PE-LogFile_labeled.csv')\n",
    "usnjrnl_output_path = os.path.join(OUTPUT_DIR, '02-PE-UsnJrnl_labeled.csv')\n",
    "\n",
    "df_logfile.to_csv(logfile_output_path, index=False)\n",
    "df_usnjrnl.to_csv(usnjrnl_output_path, index=False)\n",
    "\n",
    "print(f\"\\nLogFile saved to: {logfile_output_path}\")\n",
    "print(f\"UsnJrnl saved to: {usnjrnl_output_path}\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "print(\"Phase 1: Data Labeling Complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
