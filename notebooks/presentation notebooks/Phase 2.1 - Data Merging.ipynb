{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f46e175",
   "metadata": {},
   "source": [
    "# Phase 2.1 - Data Merging (LogFile + UsnJrnl)\n",
    "\n",
    "**Objective:** Merge the cleaned LogFile and UsnJrnl datasets into a unified temporal timeline for comprehensive forensic analysis.\n",
    "\n",
    "**Input Files:**\n",
    "- `data/processed/Phase 2 - Data Cleaning/Master_LogFile_Cleaned.csv` (83,458 records)\n",
    "- `data/processed/Phase 2 - Data Cleaning/Master_UsnJrnl_Cleaned.csv` (2,181,063 records)\n",
    "\n",
    "**Output File:**\n",
    "- `data/processed/Phase 2.1 - Data Merging/Master_Timeline.csv`\n",
    "\n",
    "**Process:**\n",
    "1. Load both cleaned master datasets\n",
    "2. Standardize column names and structure\n",
    "3. Merge LogFile and UsnJrnl into unified timeline\n",
    "4. Sort by timestamp\n",
    "5. Validate merged data\n",
    "6. Export Master_Timeline.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7235f3f6",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be693f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "Pandas version: 2.3.2\n",
      "NumPy version: 2.3.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb5f04",
   "metadata": {},
   "source": [
    "## 2. Configuration and Load Cleaned Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af977c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Directory: data/processed/Phase 2 - Data Cleaning\n",
      "Output Directory: data/processed/Phase 2.1 - Data Merging\n",
      "\n",
      "Input Files:\n",
      "  - LogFile: data/processed/Phase 2 - Data Cleaning/Master_LogFile_Cleaned.csv\n",
      "  - UsnJrnl: data/processed/Phase 2 - Data Cleaning/Master_UsnJrnl_Cleaned.csv\n",
      "\n",
      "Output File:\n",
      "  - Master Timeline: data/processed/Phase 2.1 - Data Merging/Master_Timeline.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "INPUT_DIR = Path('data/processed/Phase 2 - Data Cleaning')\n",
    "OUTPUT_DIR = Path('data/processed/Phase 2.1 - Data Merging')\n",
    "\n",
    "# Ensure output directory exists\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# File paths\n",
    "LOGFILE_PATH = INPUT_DIR / 'Master_LogFile_Cleaned.csv'\n",
    "USNJRNL_PATH = INPUT_DIR / 'Master_UsnJrnl_Cleaned.csv'\n",
    "OUTPUT_PATH = OUTPUT_DIR / 'Master_Timeline.csv'\n",
    "\n",
    "print(f\"Input Directory: {INPUT_DIR}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "print(f\"\\nInput Files:\")\n",
    "print(f\"  - LogFile: {LOGFILE_PATH}\")\n",
    "print(f\"  - UsnJrnl: {USNJRNL_PATH}\")\n",
    "print(f\"\\nOutput File:\")\n",
    "print(f\"  - Master Timeline: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff8d2a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading Master LogFile...\n",
      "============================================================\n",
      "âœ“ Master LogFile loaded successfully\n",
      "  Records: 83,458\n",
      "  Columns: 17\n",
      "  Timestomped: 14\n",
      "  Suspicious: 8\n",
      "\n",
      "Loading Master UsnJrnl...\n",
      "============================================================\n",
      "âœ“ Master UsnJrnl loaded successfully\n",
      "  Records: 2,181,063\n",
      "  Columns: 11\n",
      "  Timestomped: 238\n",
      "  Suspicious: 8\n"
     ]
    }
   ],
   "source": [
    "# --- Load Master LogFile ---\n",
    "print(\"\\nLoading Master LogFile...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    df_logfile = pd.read_csv(LOGFILE_PATH, low_memory=False)\n",
    "    \n",
    "    # Convert timestamp columns to datetime\n",
    "    timestamp_cols_logfile = ['eventtime(utc+8)', 'creationtime', 'modifiedtime', 'mftmodifiedtime', 'accessedtime']\n",
    "    for col in timestamp_cols_logfile:\n",
    "        if col in df_logfile.columns:\n",
    "            df_logfile[col] = pd.to_datetime(df_logfile[col], errors='coerce', utc=True)\n",
    "    \n",
    "    print(f\"âœ“ Master LogFile loaded successfully\")\n",
    "    print(f\"  Records: {len(df_logfile):,}\")\n",
    "    print(f\"  Columns: {len(df_logfile.columns)}\")\n",
    "    print(f\"  Timestomped: {df_logfile['is_timestomped'].sum()}\")\n",
    "    print(f\"  Suspicious: {df_logfile['is_suspicious_execution'].sum()}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"âœ— ERROR: Master LogFile not found at {LOGFILE_PATH}\")\n",
    "    df_logfile = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    print(f\"âœ— ERROR loading LogFile: {e}\")\n",
    "    df_logfile = pd.DataFrame()\n",
    "\n",
    "# --- Load Master UsnJrnl ---\n",
    "print(\"\\nLoading Master UsnJrnl...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    df_usnjrnl = pd.read_csv(USNJRNL_PATH, low_memory=False)\n",
    "    \n",
    "    # Convert timestamp column to datetime\n",
    "    if 'timestamp(utc+8)' in df_usnjrnl.columns:\n",
    "        df_usnjrnl['timestamp(utc+8)'] = pd.to_datetime(df_usnjrnl['timestamp(utc+8)'], errors='coerce', utc=True)\n",
    "    \n",
    "    print(f\"âœ“ Master UsnJrnl loaded successfully\")\n",
    "    print(f\"  Records: {len(df_usnjrnl):,}\")\n",
    "    print(f\"  Columns: {len(df_usnjrnl.columns)}\")\n",
    "    print(f\"  Timestomped: {df_usnjrnl['is_timestomped'].sum()}\")\n",
    "    print(f\"  Suspicious: {df_usnjrnl['is_suspicious_execution'].sum()}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"âœ— ERROR: Master UsnJrnl not found at {USNJRNL_PATH}\")\n",
    "    df_usnjrnl = pd.DataFrame()\n",
    "except Exception as e:\n",
    "    print(f\"âœ— ERROR loading UsnJrnl: {e}\")\n",
    "    df_usnjrnl = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c9292d",
   "metadata": {},
   "source": [
    "## 3. Examine Column Structures\n",
    "\n",
    "Before merging, let's examine the column structures of both datasets to understand how to standardize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4506a4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Structure Comparison:\n",
      "============================================================\n",
      "\n",
      "LogFile Columns (17):\n",
      "['case_id', 'lsn', 'eventtime(utc+8)', 'event', 'detail', 'file/directory name', 'full path', 'creationtime', 'modifiedtime', 'mftmodifiedtime', 'accessedtime', 'redo', 'target vcn', 'cluster index', 'is_timestomped', 'is_suspicious_execution', 'has_incomplete_timestamps']\n",
      "\n",
      "UsnJrnl Columns (11):\n",
      "['case_id', 'timestamp(utc+8)', 'usn', 'file/directory name', 'fullpath', 'eventinfo', 'fileattribute', 'filereferencenumber', 'parentfilereferencenumber', 'is_timestomped', 'is_suspicious_execution']\n",
      "\n",
      "Common Columns (4):\n",
      "['case_id', 'file/directory name', 'is_suspicious_execution', 'is_timestomped']\n",
      "\n",
      "LogFile-Only Columns (13):\n",
      "['accessedtime', 'cluster index', 'creationtime', 'detail', 'event', 'eventtime(utc+8)', 'full path', 'has_incomplete_timestamps', 'lsn', 'mftmodifiedtime', 'modifiedtime', 'redo', 'target vcn']\n",
      "\n",
      "UsnJrnl-Only Columns (7):\n",
      "['eventinfo', 'fileattribute', 'filereferencenumber', 'fullpath', 'parentfilereferencenumber', 'timestamp(utc+8)', 'usn']\n"
     ]
    }
   ],
   "source": [
    "# --- Compare column structures ---\n",
    "print(\"\\nColumn Structure Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nLogFile Columns ({len(df_logfile.columns)}):\")\n",
    "print(df_logfile.columns.tolist())\n",
    "\n",
    "print(f\"\\nUsnJrnl Columns ({len(df_usnjrnl.columns)}):\")\n",
    "print(df_usnjrnl.columns.tolist())\n",
    "\n",
    "# Find common columns\n",
    "common_cols = set(df_logfile.columns).intersection(set(df_usnjrnl.columns))\n",
    "print(f\"\\nCommon Columns ({len(common_cols)}):\")\n",
    "print(sorted(list(common_cols)))\n",
    "\n",
    "# Find unique columns\n",
    "logfile_only = set(df_logfile.columns) - set(df_usnjrnl.columns)\n",
    "usnjrnl_only = set(df_usnjrnl.columns) - set(df_logfile.columns)\n",
    "\n",
    "print(f\"\\nLogFile-Only Columns ({len(logfile_only)}):\")\n",
    "print(sorted(list(logfile_only)))\n",
    "\n",
    "print(f\"\\nUsnJrnl-Only Columns ({len(usnjrnl_only)}):\")\n",
    "print(sorted(list(usnjrnl_only)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fecca5",
   "metadata": {},
   "source": [
    "## 4. Standardize Column Names and Structure\n",
    "\n",
    "**Strategy for Merging:**\n",
    "\n",
    "1. **Add source identifier** to distinguish LogFile vs UsnJrnl records\n",
    "2. **Standardize timestamp column** - use unified primary timestamp\n",
    "3. **Handle dataset-specific columns:**\n",
    "   - LogFile-specific: `lsn`, `event`, `detail`, `redo`, MAC timestamps\n",
    "   - UsnJrnl-specific: `usn`, `eventinfo`, `fileattribute`, `filereferencenumber`, `parentfilereferencenumber`\n",
    "4. **Standardize path columns:**\n",
    "   - LogFile: `full path`\n",
    "   - UsnJrnl: `fullpath`\n",
    "   - Merge into single `fullpath` column\n",
    "\n",
    "**Approach:** Keep all columns, fill missing values with NaN where dataset-specific columns don't exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84dbdbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding source identifier columns...\n",
      "============================================================\n",
      "âœ“ Added 'source' column to LogFile: 83,458 records\n",
      "âœ“ Added 'source' column to UsnJrnl: 2,181,063 records\n",
      "\n",
      "Standardizing column names...\n",
      "============================================================\n",
      "âœ“ Renamed 'full path' â†’ 'fullpath' in LogFile\n",
      "âœ“ Created 'timestamp_primary' from 'eventtime(utc+8)' in LogFile\n",
      "âœ“ Created 'timestamp_primary' from 'timestamp(utc+8)' in UsnJrnl\n",
      "\n",
      "âœ“ Column standardization completed!\n"
     ]
    }
   ],
   "source": [
    "# --- Add source identifier to both datasets ---\n",
    "print(\"Adding source identifier columns...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df_logfile['source'] = 'LogFile'\n",
    "df_usnjrnl['source'] = 'UsnJrnl'\n",
    "\n",
    "print(f\"âœ“ Added 'source' column to LogFile: {len(df_logfile):,} records\")\n",
    "print(f\"âœ“ Added 'source' column to UsnJrnl: {len(df_usnjrnl):,} records\")\n",
    "\n",
    "# --- Standardize column names ---\n",
    "print(\"\\nStandardizing column names...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Rename 'full path' to 'fullpath' in LogFile to match UsnJrnl\n",
    "if 'full path' in df_logfile.columns:\n",
    "    df_logfile.rename(columns={'full path': 'fullpath'}, inplace=True)\n",
    "    print(\"âœ“ Renamed 'full path' â†’ 'fullpath' in LogFile\")\n",
    "\n",
    "# Create unified primary timestamp column\n",
    "# LogFile uses 'eventtime(utc+8)', UsnJrnl uses 'timestamp(utc+8)'\n",
    "# We'll create 'timestamp_primary' for both\n",
    "\n",
    "if 'eventtime(utc+8)' in df_logfile.columns:\n",
    "    df_logfile['timestamp_primary'] = df_logfile['eventtime(utc+8)']\n",
    "    print(\"âœ“ Created 'timestamp_primary' from 'eventtime(utc+8)' in LogFile\")\n",
    "\n",
    "if 'timestamp(utc+8)' in df_usnjrnl.columns:\n",
    "    df_usnjrnl['timestamp_primary'] = df_usnjrnl['timestamp(utc+8)']\n",
    "    print(\"âœ“ Created 'timestamp_primary' from 'timestamp(utc+8)' in UsnJrnl\")\n",
    "\n",
    "print(\"\\nâœ“ Column standardization completed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdead02e",
   "metadata": {},
   "source": [
    "## 5. Merge Datasets into Unified Timeline\n",
    "\n",
    "Concatenate LogFile and UsnJrnl vertically, preserving all columns from both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3dbbbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merging LogFile and UsnJrnl into unified timeline...\n",
      "============================================================\n",
      "âœ“ Datasets merged successfully!\n",
      "\n",
      "Merge Statistics:\n",
      "  LogFile records:           83,458\n",
      "  UsnJrnl records:        2,181,063\n",
      "  ----------------------------------------\n",
      "  Master Timeline:        2,264,521\n",
      "\n",
      "  Total columns:       25\n"
     ]
    }
   ],
   "source": [
    "# --- Merge LogFile and UsnJrnl ---\n",
    "print(\"\\nMerging LogFile and UsnJrnl into unified timeline...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Concatenate vertically (rows)\n",
    "master_timeline = pd.concat([df_logfile, df_usnjrnl], ignore_index=True, sort=False)\n",
    "\n",
    "print(f\"âœ“ Datasets merged successfully!\")\n",
    "print(f\"\\nMerge Statistics:\")\n",
    "print(f\"  LogFile records:     {len(df_logfile):>12,}\")\n",
    "print(f\"  UsnJrnl records:     {len(df_usnjrnl):>12,}\")\n",
    "print(f\"  ----------------------------------------\")\n",
    "print(f\"  Master Timeline:     {len(master_timeline):>12,}\")\n",
    "print(f\"\\n  Total columns:       {len(master_timeline.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19e57a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verifying merge integrity...\n",
      "============================================================\n",
      "\n",
      "Source Distribution:\n",
      "  UsnJrnl       2,181,063 ( 96.31%)\n",
      "  LogFile          83,458 (  3.69%)\n",
      "\n",
      "Labeled Rows Preservation:\n",
      "  Timestomped:                  252\n",
      "  Suspicious:                    16\n",
      "  Total Labeled:                268\n",
      "\n",
      "âœ“ All labeled rows preserved correctly!\n"
     ]
    }
   ],
   "source": [
    "# --- Verify merge integrity ---\n",
    "print(\"\\nVerifying merge integrity...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check source distribution\n",
    "source_counts = master_timeline['source'].value_counts()\n",
    "print(f\"\\nSource Distribution:\")\n",
    "for source, count in source_counts.items():\n",
    "    pct = (count / len(master_timeline)) * 100\n",
    "    print(f\"  {source:<10} {count:>12,} ({pct:>6.2f}%)\")\n",
    "\n",
    "# Check labeled rows preservation\n",
    "total_timestomped = master_timeline['is_timestomped'].sum()\n",
    "total_suspicious = master_timeline['is_suspicious_execution'].sum()\n",
    "\n",
    "print(f\"\\nLabeled Rows Preservation:\")\n",
    "print(f\"  Timestomped:         {total_timestomped:>12}\")\n",
    "print(f\"  Suspicious:          {total_suspicious:>12}\")\n",
    "print(f\"  Total Labeled:       {total_timestomped + total_suspicious:>12}\")\n",
    "\n",
    "# Expected: 14 + 238 = 252 timestomped, 8 + 8 = 16 suspicious\n",
    "expected_timestomped = df_logfile['is_timestomped'].sum() + df_usnjrnl['is_timestomped'].sum()\n",
    "expected_suspicious = df_logfile['is_suspicious_execution'].sum() + df_usnjrnl['is_suspicious_execution'].sum()\n",
    "\n",
    "if total_timestomped == expected_timestomped and total_suspicious == expected_suspicious:\n",
    "    print(\"\\nâœ“ All labeled rows preserved correctly!\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸ WARNING: Expected {expected_timestomped} timestomped and {expected_suspicious} suspicious\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a4cebe",
   "metadata": {},
   "source": [
    "## 6. Sort by Timestamp and Case ID\n",
    "\n",
    "Sort the unified timeline chronologically by primary timestamp and case_id for logical ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abffcf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sorting Master Timeline...\n",
      "============================================================\n",
      "âœ“ Master Timeline sorted by case_id and timestamp_primary\n",
      "\n",
      "Temporal Coverage:\n",
      "  Earliest event: 2000-01-01 08:00:00+00:00\n",
      "  Latest event:   2024-01-01 00:08:36+00:00\n",
      "  Time span:      8765 days (~24.0 years)\n"
     ]
    }
   ],
   "source": [
    "# --- Sort master timeline ---\n",
    "print(\"\\nSorting Master Timeline...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sort by case_id and timestamp_primary\n",
    "master_timeline = master_timeline.sort_values(\n",
    "    ['case_id', 'timestamp_primary'], \n",
    "    na_position='last'\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"âœ“ Master Timeline sorted by case_id and timestamp_primary\")\n",
    "\n",
    "# Display temporal coverage\n",
    "print(f\"\\nTemporal Coverage:\")\n",
    "earliest = master_timeline['timestamp_primary'].min()\n",
    "latest = master_timeline['timestamp_primary'].max()\n",
    "\n",
    "print(f\"  Earliest event: {earliest}\")\n",
    "print(f\"  Latest event:   {latest}\")\n",
    "\n",
    "if pd.notna(earliest) and pd.notna(latest):\n",
    "    duration = latest - earliest\n",
    "    print(f\"  Time span:      {duration.days} days (~{duration.days/365:.1f} years)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76934484",
   "metadata": {},
   "source": [
    "## 7. Reorder Columns for Better Readability\n",
    "\n",
    "Place the most important columns first for easier analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7df1d921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reordering columns...\n",
      "============================================================\n",
      "âœ“ Columns reordered\n",
      "\n",
      "First 10 columns:\n",
      "['case_id', 'timestamp_primary', 'source', 'fullpath', 'file/directory name', 'is_timestomped', 'is_suspicious_execution', 'lsn', 'eventtime(utc+8)', 'event']\n"
     ]
    }
   ],
   "source": [
    "# --- Reorder columns logically ---\n",
    "print(\"\\nReordering columns...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define preferred column order\n",
    "priority_cols = [\n",
    "    'case_id',\n",
    "    'timestamp_primary',\n",
    "    'source',\n",
    "    'fullpath',\n",
    "    'file/directory name',\n",
    "    'is_timestomped',\n",
    "    'is_suspicious_execution'\n",
    "]\n",
    "\n",
    "# Get remaining columns\n",
    "remaining_cols = [col for col in master_timeline.columns if col not in priority_cols]\n",
    "\n",
    "# Combine: priority columns first, then remaining\n",
    "final_col_order = priority_cols + remaining_cols\n",
    "\n",
    "# Reorder (only include columns that exist)\n",
    "final_col_order = [col for col in final_col_order if col in master_timeline.columns]\n",
    "\n",
    "master_timeline = master_timeline[final_col_order]\n",
    "\n",
    "print(\"âœ“ Columns reordered\")\n",
    "print(f\"\\nFirst 10 columns:\")\n",
    "print(master_timeline.columns.tolist()[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d972f9",
   "metadata": {},
   "source": [
    "## 8. Final Validation and Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf7b1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Master Timeline Validation\n",
      "============================================================\n",
      "Total records: 2,264,521\n",
      "Total columns: 25\n",
      "\n",
      "Records per Case:\n",
      "  Case 01:    242,400\n",
      "  Case 02:    145,435\n",
      "  Case 03:    144,938\n",
      "  Case 04:    226,352\n",
      "  Case 05:    228,078\n",
      "  Case 06:    227,209\n",
      "  Case 07:    147,593\n",
      "  Case 08:    148,019\n",
      "  Case 09:    149,569\n",
      "  Case 10:    149,150\n",
      "  Case 11:    227,331\n",
      "  Case 12:    228,447\n",
      "\n",
      "Source Breakdown per Case:\n",
      "Case     LogFile      UsnJrnl      Total       \n",
      "--------------------------------------------------\n",
      "Case 01  13,763       228,637      242,400     \n",
      "Case 02  6,049        139,386      145,435     \n",
      "Case 03  7,262        137,676      144,938     \n",
      "Case 04  4,859        221,493      226,352     \n",
      "Case 05  4,909        223,169      228,078     \n",
      "Case 06  4,703        222,506      227,209     \n",
      "Case 07  7,823        139,770      147,593     \n",
      "Case 08  7,666        140,353      148,019     \n",
      "Case 09  8,453        141,116      149,569     \n",
      "Case 10  8,073        141,077      149,150     \n",
      "Case 11  4,898        222,433      227,331     \n",
      "Case 12  5,000        223,447      228,447     \n",
      "\n",
      "Data Completeness:\n",
      "  timestamp_primary: 2,264,513 / 2,264,521 (100.00%)\n",
      "  fullpath: 2,037,872 / 2,264,521 (89.99%)\n",
      "\n",
      "============================================================\n",
      "âœ“ Validation completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- Final validation ---\n",
    "print(\"\\nFinal Master Timeline Validation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Total records: {len(master_timeline):,}\")\n",
    "print(f\"Total columns: {len(master_timeline.columns)}\")\n",
    "\n",
    "# Per-case distribution\n",
    "print(f\"\\nRecords per Case:\")\n",
    "case_counts = master_timeline['case_id'].value_counts().sort_index()\n",
    "for case_id, count in case_counts.items():\n",
    "    print(f\"  Case {case_id:02d}: {count:>10,}\")\n",
    "\n",
    "# Source breakdown per case\n",
    "print(f\"\\nSource Breakdown per Case:\")\n",
    "print(f\"{'Case':<8} {'LogFile':<12} {'UsnJrnl':<12} {'Total':<12}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for case_id in sorted(master_timeline['case_id'].unique()):\n",
    "    case_data = master_timeline[master_timeline['case_id'] == case_id]\n",
    "    logfile_count = len(case_data[case_data['source'] == 'LogFile'])\n",
    "    usnjrnl_count = len(case_data[case_data['source'] == 'UsnJrnl'])\n",
    "    total_count = len(case_data)\n",
    "    \n",
    "    print(f\"Case {case_id:02d}  {logfile_count:<12,} {usnjrnl_count:<12,} {total_count:<12,}\")\n",
    "\n",
    "# Data completeness check\n",
    "print(f\"\\nData Completeness:\")\n",
    "print(f\"  timestamp_primary: {master_timeline['timestamp_primary'].notna().sum():,} / {len(master_timeline):,} ({master_timeline['timestamp_primary'].notna().sum()/len(master_timeline)*100:.2f}%)\")\n",
    "print(f\"  fullpath: {master_timeline['fullpath'].notna().sum():,} / {len(master_timeline):,} ({master_timeline['fullpath'].notna().sum()/len(master_timeline)*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ“ Validation completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2083c074",
   "metadata": {},
   "source": [
    "## 9. Export Master Timeline to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55b950aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exporting Master Timeline to CSV...\n",
      "============================================================\n",
      "âœ“ Master Timeline exported successfully!\n",
      "\n",
      "File Details:\n",
      "  Location: data/processed/Phase 2.1 - Data Merging/Master_Timeline.csv\n",
      "  Size: 643.65 MB\n",
      "  Records: 2,264,521\n",
      "  Columns: 25\n",
      "\n",
      "âœ“ File verified at: data/processed/Phase 2.1 - Data Merging/Master_Timeline.csv\n"
     ]
    }
   ],
   "source": [
    "# --- Export Master Timeline ---\n",
    "print(\"\\nExporting Master Timeline to CSV...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Export with proper datetime formatting\n",
    "master_timeline.to_csv(\n",
    "    OUTPUT_PATH,\n",
    "    index=False,\n",
    "    date_format='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# Get file size\n",
    "import os\n",
    "file_size_bytes = os.path.getsize(OUTPUT_PATH)\n",
    "file_size_mb = file_size_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"âœ“ Master Timeline exported successfully!\")\n",
    "print(f\"\\nFile Details:\")\n",
    "print(f\"  Location: {OUTPUT_PATH}\")\n",
    "print(f\"  Size: {file_size_mb:.2f} MB\")\n",
    "print(f\"  Records: {len(master_timeline):,}\")\n",
    "print(f\"  Columns: {len(master_timeline.columns)}\")\n",
    "\n",
    "# Verify file exists\n",
    "if OUTPUT_PATH.exists():\n",
    "    print(f\"\\nâœ“ File verified at: {OUTPUT_PATH}\")\n",
    "else:\n",
    "    print(f\"\\nâœ— Error: File not found at {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad6b35d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample of Master_Timeline.csv (First 10 rows):\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>timestamp_primary</th>\n",
       "      <th>source</th>\n",
       "      <th>fullpath</th>\n",
       "      <th>file/directory name</th>\n",
       "      <th>is_timestomped</th>\n",
       "      <th>is_suspicious_execution</th>\n",
       "      <th>lsn</th>\n",
       "      <th>eventtime(utc+8)</th>\n",
       "      <th>event</th>\n",
       "      <th>detail</th>\n",
       "      <th>creationtime</th>\n",
       "      <th>modifiedtime</th>\n",
       "      <th>mftmodifiedtime</th>\n",
       "      <th>accessedtime</th>\n",
       "      <th>redo</th>\n",
       "      <th>target vcn</th>\n",
       "      <th>cluster index</th>\n",
       "      <th>has_incomplete_timestamps</th>\n",
       "      <th>timestamp(utc+8)</th>\n",
       "      <th>usn</th>\n",
       "      <th>eventinfo</th>\n",
       "      <th>fileattribute</th>\n",
       "      <th>filereferencenumber</th>\n",
       "      <th>parentfilereferencenumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-01 08:00:00+00:00</td>\n",
       "      <td>LogFile</td>\n",
       "      <td>\\Program Files (x86)\\Dropbox\\Client\\189.4.8395...</td>\n",
       "      <td>style.js</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.715607e+09</td>\n",
       "      <td>2000-01-01 08:00:00+00:00</td>\n",
       "      <td>Updating MFTModified Time</td>\n",
       "      <td>MFTModifiedTime : 2023-12-23 00:14:24 -&gt; 2023-...</td>\n",
       "      <td>2023-12-23 00:14:24+00:00</td>\n",
       "      <td>2000-01-01 08:00:00+00:00</td>\n",
       "      <td>2023-12-23 00:14:52+00:00</td>\n",
       "      <td>2023-12-23 00:14:24+00:00</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x174F8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-01 08:00:00+00:00</td>\n",
       "      <td>LogFile</td>\n",
       "      <td>\\Program Files (x86)\\Dropbox\\Client\\189.4.8395...</td>\n",
       "      <td>CalendarUtils.js</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.724385e+09</td>\n",
       "      <td>2000-01-01 08:00:00+00:00</td>\n",
       "      <td>Updating MFTModified Time</td>\n",
       "      <td>MFTModifiedTime : 2023-12-23 00:14:24 -&gt; 2023-...</td>\n",
       "      <td>2023-12-23 00:14:24+00:00</td>\n",
       "      <td>2000-01-01 08:00:00+00:00</td>\n",
       "      <td>2023-12-23 00:15:26+00:00</td>\n",
       "      <td>2023-12-23 00:14:24+00:00</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x174F3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2000-01-01 08:00:00+00:00</td>\n",
       "      <td>LogFile</td>\n",
       "      <td>\\Program Files (x86)\\Dropbox\\Client\\189.4.8395...</td>\n",
       "      <td>StackView.js</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.724811e+09</td>\n",
       "      <td>2000-01-01 08:00:00+00:00</td>\n",
       "      <td>Updating MFTModified Time</td>\n",
       "      <td>MFTModifiedTime : 2023-12-23 00:14:24 -&gt; 2023-...</td>\n",
       "      <td>2023-12-23 00:14:24+00:00</td>\n",
       "      <td>2000-01-01 08:00:00+00:00</td>\n",
       "      <td>2023-12-23 00:16:08+00:00</td>\n",
       "      <td>2023-12-23 00:14:24+00:00</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x174F8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-10-11 14:08:00+00:00</td>\n",
       "      <td>LogFile</td>\n",
       "      <td>\\Users\\blueangel\\AppData\\Local\\Temp\\RarSFX1\\Wi...</td>\n",
       "      <td>WinHex.exe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.724891e+09</td>\n",
       "      <td>2010-10-11 14:08:00+00:00</td>\n",
       "      <td>Updating MFTModified Time</td>\n",
       "      <td>MFTModifiedTime : 2023-12-23 00:16:12 -&gt; 2023-...</td>\n",
       "      <td>2023-12-23 00:16:12+00:00</td>\n",
       "      <td>2010-10-11 14:08:00+00:00</td>\n",
       "      <td>2023-12-23 00:16:13+00:00</td>\n",
       "      <td>2023-12-23 00:16:13+00:00</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x7E20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-10-11 14:08:00+00:00</td>\n",
       "      <td>LogFile</td>\n",
       "      <td>\\Users\\blueangel\\AppData\\Local\\Temp\\RarSFX1\\se...</td>\n",
       "      <td>setup.exe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.725322e+09</td>\n",
       "      <td>2010-10-11 14:08:00+00:00</td>\n",
       "      <td>Updating MFTModified Time</td>\n",
       "      <td>MFTModifiedTime : 2023-12-23 00:16:12 -&gt; 2023-...</td>\n",
       "      <td>2023-12-23 00:16:12+00:00</td>\n",
       "      <td>2010-10-11 14:08:00+00:00</td>\n",
       "      <td>2023-12-23 00:16:17+00:00</td>\n",
       "      <td>2023-12-23 00:16:12+00:00</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x7E1F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-07 22:58:27+00:00</td>\n",
       "      <td>LogFile</td>\n",
       "      <td>\\Windows\\WinSxS\\amd64_windows-shield-provider_...</td>\n",
       "      <td>SecurityHealthHost.exe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.726152e+09</td>\n",
       "      <td>2019-12-07 22:58:27+00:00</td>\n",
       "      <td>Writing Content of Resident File</td>\n",
       "      <td>Writing Size : 340</td>\n",
       "      <td>2019-12-07 22:55:42+00:00</td>\n",
       "      <td>2019-12-07 22:58:27+00:00</td>\n",
       "      <td>2022-12-16 16:11:29+00:00</td>\n",
       "      <td>2019-12-07 22:58:27+00:00</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x4ED2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-07 22:59:41+00:00</td>\n",
       "      <td>LogFile</td>\n",
       "      <td>\\Program Files\\WindowsApps\\Microsoft.XboxIdent...</td>\n",
       "      <td>clrcompression.dll</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.724616e+09</td>\n",
       "      <td>2019-12-07 22:59:41+00:00</td>\n",
       "      <td>Updating MFTModified Time</td>\n",
       "      <td>MFTModifiedTime : 2022-12-21 01:16:54 -&gt; 2023-...</td>\n",
       "      <td>2019-12-07 22:59:41+00:00</td>\n",
       "      <td>2019-12-07 22:59:41+00:00</td>\n",
       "      <td>2023-12-23 00:15:45+00:00</td>\n",
       "      <td>2023-12-23 00:15:45+00:00</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x1C72</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-09-08 11:18:48+00:00</td>\n",
       "      <td>LogFile</td>\n",
       "      <td>\\Windows\\WinSxS\\amd64_windows-shield-provider_...</td>\n",
       "      <td>SecurityHealthAgent.dll</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.726153e+09</td>\n",
       "      <td>2022-09-08 11:18:48+00:00</td>\n",
       "      <td>Writing Content of Resident File</td>\n",
       "      <td>Writing Size : 264</td>\n",
       "      <td>2022-09-08 11:13:08+00:00</td>\n",
       "      <td>2022-09-08 11:18:48+00:00</td>\n",
       "      <td>2022-12-16 16:11:27+00:00</td>\n",
       "      <td>2022-09-08 11:18:48+00:00</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x4C2B</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-27 19:52:30+00:00</td>\n",
       "      <td>LogFile</td>\n",
       "      <td>\\Program Files\\Common Files\\microsoft shared\\C...</td>\n",
       "      <td>AppVClient.man</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.726886e+09</td>\n",
       "      <td>2022-10-27 19:52:30+00:00</td>\n",
       "      <td>Updating MFTModified Time</td>\n",
       "      <td>MFTModifiedTime : 2023-04-19 10:15:17 -&gt; 2023-...</td>\n",
       "      <td>2022-12-21 21:44:51+00:00</td>\n",
       "      <td>2022-10-27 19:52:30+00:00</td>\n",
       "      <td>2023-12-23 00:18:03+00:00</td>\n",
       "      <td>2023-12-23 00:17:48+00:00</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x147BA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-10-27 19:52:30+00:00</td>\n",
       "      <td>LogFile</td>\n",
       "      <td>\\Program Files\\Common Files\\microsoft shared\\C...</td>\n",
       "      <td>AppVClientIsv.man</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.726886e+09</td>\n",
       "      <td>2022-10-27 19:52:30+00:00</td>\n",
       "      <td>Updating MFTModified Time</td>\n",
       "      <td>MFTModifiedTime : 2023-04-19 10:15:17 -&gt; 2023-...</td>\n",
       "      <td>2022-12-21 21:44:51+00:00</td>\n",
       "      <td>2022-10-27 19:52:30+00:00</td>\n",
       "      <td>2023-12-23 00:18:03+00:00</td>\n",
       "      <td>2023-12-23 00:17:48+00:00</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x147BA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   case_id         timestamp_primary   source  \\\n",
       "0        1 2000-01-01 08:00:00+00:00  LogFile   \n",
       "1        1 2000-01-01 08:00:00+00:00  LogFile   \n",
       "2        1 2000-01-01 08:00:00+00:00  LogFile   \n",
       "3        1 2010-10-11 14:08:00+00:00  LogFile   \n",
       "4        1 2010-10-11 14:08:00+00:00  LogFile   \n",
       "5        1 2019-12-07 22:58:27+00:00  LogFile   \n",
       "6        1 2019-12-07 22:59:41+00:00  LogFile   \n",
       "7        1 2022-09-08 11:18:48+00:00  LogFile   \n",
       "8        1 2022-10-27 19:52:30+00:00  LogFile   \n",
       "9        1 2022-10-27 19:52:30+00:00  LogFile   \n",
       "\n",
       "                                            fullpath      file/directory name  \\\n",
       "0  \\Program Files (x86)\\Dropbox\\Client\\189.4.8395...                 style.js   \n",
       "1  \\Program Files (x86)\\Dropbox\\Client\\189.4.8395...         CalendarUtils.js   \n",
       "2  \\Program Files (x86)\\Dropbox\\Client\\189.4.8395...             StackView.js   \n",
       "3  \\Users\\blueangel\\AppData\\Local\\Temp\\RarSFX1\\Wi...               WinHex.exe   \n",
       "4  \\Users\\blueangel\\AppData\\Local\\Temp\\RarSFX1\\se...                setup.exe   \n",
       "5  \\Windows\\WinSxS\\amd64_windows-shield-provider_...   SecurityHealthHost.exe   \n",
       "6  \\Program Files\\WindowsApps\\Microsoft.XboxIdent...       clrcompression.dll   \n",
       "7  \\Windows\\WinSxS\\amd64_windows-shield-provider_...  SecurityHealthAgent.dll   \n",
       "8  \\Program Files\\Common Files\\microsoft shared\\C...           AppVClient.man   \n",
       "9  \\Program Files\\Common Files\\microsoft shared\\C...        AppVClientIsv.man   \n",
       "\n",
       "   is_timestomped  is_suspicious_execution           lsn  \\\n",
       "0               0                        0  8.715607e+09   \n",
       "1               0                        0  8.724385e+09   \n",
       "2               0                        0  8.724811e+09   \n",
       "3               0                        0  8.724891e+09   \n",
       "4               0                        0  8.725322e+09   \n",
       "5               0                        0  8.726152e+09   \n",
       "6               0                        0  8.724616e+09   \n",
       "7               0                        0  8.726153e+09   \n",
       "8               0                        0  8.726886e+09   \n",
       "9               0                        0  8.726886e+09   \n",
       "\n",
       "           eventtime(utc+8)                             event  \\\n",
       "0 2000-01-01 08:00:00+00:00         Updating MFTModified Time   \n",
       "1 2000-01-01 08:00:00+00:00         Updating MFTModified Time   \n",
       "2 2000-01-01 08:00:00+00:00         Updating MFTModified Time   \n",
       "3 2010-10-11 14:08:00+00:00         Updating MFTModified Time   \n",
       "4 2010-10-11 14:08:00+00:00         Updating MFTModified Time   \n",
       "5 2019-12-07 22:58:27+00:00  Writing Content of Resident File   \n",
       "6 2019-12-07 22:59:41+00:00         Updating MFTModified Time   \n",
       "7 2022-09-08 11:18:48+00:00  Writing Content of Resident File   \n",
       "8 2022-10-27 19:52:30+00:00         Updating MFTModified Time   \n",
       "9 2022-10-27 19:52:30+00:00         Updating MFTModified Time   \n",
       "\n",
       "                                              detail  \\\n",
       "0  MFTModifiedTime : 2023-12-23 00:14:24 -> 2023-...   \n",
       "1  MFTModifiedTime : 2023-12-23 00:14:24 -> 2023-...   \n",
       "2  MFTModifiedTime : 2023-12-23 00:14:24 -> 2023-...   \n",
       "3  MFTModifiedTime : 2023-12-23 00:16:12 -> 2023-...   \n",
       "4  MFTModifiedTime : 2023-12-23 00:16:12 -> 2023-...   \n",
       "5                                 Writing Size : 340   \n",
       "6  MFTModifiedTime : 2022-12-21 01:16:54 -> 2023-...   \n",
       "7                                 Writing Size : 264   \n",
       "8  MFTModifiedTime : 2023-04-19 10:15:17 -> 2023-...   \n",
       "9  MFTModifiedTime : 2023-04-19 10:15:17 -> 2023-...   \n",
       "\n",
       "               creationtime              modifiedtime  \\\n",
       "0 2023-12-23 00:14:24+00:00 2000-01-01 08:00:00+00:00   \n",
       "1 2023-12-23 00:14:24+00:00 2000-01-01 08:00:00+00:00   \n",
       "2 2023-12-23 00:14:24+00:00 2000-01-01 08:00:00+00:00   \n",
       "3 2023-12-23 00:16:12+00:00 2010-10-11 14:08:00+00:00   \n",
       "4 2023-12-23 00:16:12+00:00 2010-10-11 14:08:00+00:00   \n",
       "5 2019-12-07 22:55:42+00:00 2019-12-07 22:58:27+00:00   \n",
       "6 2019-12-07 22:59:41+00:00 2019-12-07 22:59:41+00:00   \n",
       "7 2022-09-08 11:13:08+00:00 2022-09-08 11:18:48+00:00   \n",
       "8 2022-12-21 21:44:51+00:00 2022-10-27 19:52:30+00:00   \n",
       "9 2022-12-21 21:44:51+00:00 2022-10-27 19:52:30+00:00   \n",
       "\n",
       "            mftmodifiedtime              accessedtime                   redo  \\\n",
       "0 2023-12-23 00:14:52+00:00 2023-12-23 00:14:24+00:00  Update Resident Value   \n",
       "1 2023-12-23 00:15:26+00:00 2023-12-23 00:14:24+00:00  Update Resident Value   \n",
       "2 2023-12-23 00:16:08+00:00 2023-12-23 00:14:24+00:00  Update Resident Value   \n",
       "3 2023-12-23 00:16:13+00:00 2023-12-23 00:16:13+00:00  Update Resident Value   \n",
       "4 2023-12-23 00:16:17+00:00 2023-12-23 00:16:12+00:00  Update Resident Value   \n",
       "5 2022-12-16 16:11:29+00:00 2019-12-07 22:58:27+00:00  Update Resident Value   \n",
       "6 2023-12-23 00:15:45+00:00 2023-12-23 00:15:45+00:00  Update Resident Value   \n",
       "7 2022-12-16 16:11:27+00:00 2022-09-08 11:18:48+00:00  Update Resident Value   \n",
       "8 2023-12-23 00:18:03+00:00 2023-12-23 00:17:48+00:00  Update Resident Value   \n",
       "9 2023-12-23 00:18:03+00:00 2023-12-23 00:17:48+00:00  Update Resident Value   \n",
       "\n",
       "  target vcn  cluster index  has_incomplete_timestamps timestamp(utc+8)  usn  \\\n",
       "0    0x174F8            4.0                        0.0              NaT  NaN   \n",
       "1    0x174F3            6.0                        0.0              NaT  NaN   \n",
       "2    0x174F8            0.0                        0.0              NaT  NaN   \n",
       "3     0x7E20            4.0                        0.0              NaT  NaN   \n",
       "4     0x7E1F            2.0                        0.0              NaT  NaN   \n",
       "5     0x4ED2            2.0                        0.0              NaT  NaN   \n",
       "6     0x1C72            2.0                        0.0              NaT  NaN   \n",
       "7     0x4C2B            2.0                        0.0              NaT  NaN   \n",
       "8    0x147BA            0.0                        0.0              NaT  NaN   \n",
       "9    0x147BA            2.0                        0.0              NaT  NaN   \n",
       "\n",
       "  eventinfo fileattribute filereferencenumber parentfilereferencenumber  \n",
       "0       NaN           NaN                 NaN                       NaN  \n",
       "1       NaN           NaN                 NaN                       NaN  \n",
       "2       NaN           NaN                 NaN                       NaN  \n",
       "3       NaN           NaN                 NaN                       NaN  \n",
       "4       NaN           NaN                 NaN                       NaN  \n",
       "5       NaN           NaN                 NaN                       NaN  \n",
       "6       NaN           NaN                 NaN                       NaN  \n",
       "7       NaN           NaN                 NaN                       NaN  \n",
       "8       NaN           NaN                 NaN                       NaN  \n",
       "9       NaN           NaN                 NaN                       NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Display sample of merged timeline ---\n",
    "print(\"\\nSample of Master_Timeline.csv (First 10 rows):\")\n",
    "print(\"=\" * 60)\n",
    "master_timeline.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38783c2b",
   "metadata": {},
   "source": [
    "## Phase 2.1 - Data Merging Summary\n",
    "\n",
    "### âœ… Completed Tasks:\n",
    "\n",
    "1. **Loaded cleaned datasets:**\n",
    "   - Master_LogFile_Cleaned.csv: 83,458 records\n",
    "   - Master_UsnJrnl_Cleaned.csv: 2,181,063 records\n",
    "\n",
    "2. **Standardized structure:**\n",
    "   - Added `source` column (LogFile/UsnJrnl identifier)\n",
    "   - Created unified `timestamp_primary` column\n",
    "   - Standardized `fullpath` column name\n",
    "\n",
    "3. **Merged datasets:**\n",
    "   - Combined LogFile + UsnJrnl vertically\n",
    "   - Preserved all columns from both sources\n",
    "   - Total: 2,264,521 records\n",
    "\n",
    "4. **Sorted timeline:**\n",
    "   - Ordered by case_id and timestamp_primary\n",
    "   - Chronological event ordering\n",
    "\n",
    "5. **Validated integrity:**\n",
    "   - All labeled rows preserved\n",
    "   - Source distribution verified\n",
    "   - Data completeness checked\n",
    "\n",
    "### ðŸ“Š Master Timeline Metrics:\n",
    "\n",
    "**Total Records:** 2,264,521\n",
    "- LogFile: 83,458 (3.7%)\n",
    "- UsnJrnl: 2,181,063 (96.3%)\n",
    "\n",
    "**Labeled Rows:** \n",
    "- Timestomped: 252\n",
    "- Suspicious: 16\n",
    "- Total: 268\n",
    "\n",
    "**Temporal Coverage:** ~24 years of forensic timeline data\n",
    "\n",
    "### ðŸŽ¯ Ready for Phase 3:\n",
    "\n",
    "**Output File:** `data/processed/Phase 2.1 - Data Merging/Master_Timeline.csv`\n",
    "\n",
    "**Next Phase:** Feature Engineering\n",
    "- Calculate time delta features\n",
    "- Extract temporal patterns\n",
    "- Prepare features for ML model training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
