{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88a6c61a",
   "metadata": {},
   "source": [
    "# Part 1: Data Import and Initial Exploration (Raw Data) \n",
    "This first notebook is for getting the data into memory and a quick first look."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21770230",
   "metadata": {},
   "source": [
    "## Data Import & Initial Exploration (Raw Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a3b9b4",
   "metadata": {},
   "source": [
    "### 1. Code Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5361c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set display options for better data visibility\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x) # Keeps floats clean\n",
    "\n",
    "# Define file paths (adjust these to your actual file names and locations)\n",
    "# Assuming you've already parsed LogFile and UsnJrnl into a clean CSV format\n",
    "# This is a crucial step *before* this notebook for getting structured data.\n",
    "log_file_path = 'data/raw/01-PE-LogFile.csv'\n",
    "usnjrnl_path = 'data/raw/01-PE-UsnJrnl.csv'\n",
    "# A combined/merged dataset might also be useful if you've done that already\n",
    "combined_path = 'data/raw/combined_01PE.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae22aa2",
   "metadata": {},
   "source": [
    "### 2. Import the CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "deb79e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogFile data loaded successfully. Shape: (39077, 13)\n",
      "UsnJrnl data loaded successfully. Shape: (316817, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "try:\n",
    "    df_log = pd.read_csv(log_file_path)\n",
    "    print(f\"LogFile data loaded successfully. Shape: {df_log.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: LogFile CSV not found at {log_file_path}\")\n",
    "\n",
    "try:\n",
    "    df_usn = pd.read_csv(usnjrnl_path)\n",
    "    print(f\"UsnJrnl data loaded successfully. Shape: {df_usn.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: UsnJrnl CSV not found at {usnjrnl_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3f9448",
   "metadata": {},
   "source": [
    "### 3. Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c162dbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LogFile Initial Inspection ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSN</th>\n",
       "      <th>EventTime(UTC+8)</th>\n",
       "      <th>Event</th>\n",
       "      <th>Detail</th>\n",
       "      <th>File/Directory Name</th>\n",
       "      <th>Full Path</th>\n",
       "      <th>CreationTime</th>\n",
       "      <th>ModifiedTime</th>\n",
       "      <th>MFTModifiedTime</th>\n",
       "      <th>AccessedTime</th>\n",
       "      <th>Redo</th>\n",
       "      <th>Target VCN</th>\n",
       "      <th>Cluster Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8713791615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dropboxstatus-connecting@2x.png</td>\n",
       "      <td>\\Program Files (x86)\\Dropbox\\Client\\189.4.8395...</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>1/1/00 8:00:00</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x170EF</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8713791717</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>File Creation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dropboxstatus-connecting@3x.png</td>\n",
       "      <td>\\Program Files (x86)\\Dropbox\\Client\\189.4.8395...</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>Initialize File Record Segment</td>\n",
       "      <td>0x170EF</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8713791937</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>Writing Content of Resident File</td>\n",
       "      <td>Writing Size : 516</td>\n",
       "      <td>dropboxstatus-connecting@3x.png</td>\n",
       "      <td>\\Program Files (x86)\\Dropbox\\Client\\189.4.8395...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x170EF</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8713792122</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>Time Reversal Event</td>\n",
       "      <td>ModifiedTime : 2023-12-23 00:14:23 -&gt; 2000-01-...</td>\n",
       "      <td>dropboxstatus-connecting@3x.png</td>\n",
       "      <td>\\Program Files (x86)\\Dropbox\\Client\\189.4.8395...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x170EF</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8713792351</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dropboxstatus-connecting@3x.png</td>\n",
       "      <td>\\Program Files (x86)\\Dropbox\\Client\\189.4.8395...</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>1/1/00 8:00:00</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>Update Resident Value</td>\n",
       "      <td>0x170EF</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LSN  EventTime(UTC+8)                             Event                                             Detail              File/Directory Name                                          Full Path      CreationTime      ModifiedTime   MFTModifiedTime      AccessedTime                            Redo Target VCN  Cluster Index\n",
       "0  8713791615               NaN                               NaN                                                NaN  dropboxstatus-connecting@2x.png  \\Program Files (x86)\\Dropbox\\Client\\189.4.8395...  12/23/23 0:14:23    1/1/00 8:00:00  12/23/23 0:14:23  12/23/23 0:14:23           Update Resident Value    0x170EF              2\n",
       "1  8713791717  12/23/23 0:14:23                     File Creation                                                NaN  dropboxstatus-connecting@3x.png  \\Program Files (x86)\\Dropbox\\Client\\189.4.8395...  12/23/23 0:14:23  12/23/23 0:14:23  12/23/23 0:14:23  12/23/23 0:14:23  Initialize File Record Segment    0x170EF              6\n",
       "2  8713791937  12/23/23 0:14:23  Writing Content of Resident File                                 Writing Size : 516  dropboxstatus-connecting@3x.png  \\Program Files (x86)\\Dropbox\\Client\\189.4.8395...               NaN               NaN               NaN               NaN           Update Resident Value    0x170EF              6\n",
       "3  8713792122  12/23/23 0:14:23               Time Reversal Event  ModifiedTime : 2023-12-23 00:14:23 -> 2000-01-...  dropboxstatus-connecting@3x.png  \\Program Files (x86)\\Dropbox\\Client\\189.4.8395...               NaN               NaN               NaN               NaN           Update Resident Value    0x170EF              6\n",
       "4  8713792351  12/23/23 0:14:23                               NaN                                                NaN  dropboxstatus-connecting@3x.png  \\Program Files (x86)\\Dropbox\\Client\\189.4.8395...  12/23/23 0:14:23    1/1/00 8:00:00  12/23/23 0:14:23  12/23/23 0:14:23           Update Resident Value    0x170EF              6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39077 entries, 0 to 39076\n",
      "Columns: 13 entries, LSN to Cluster Index\n",
      "dtypes: int64(2), object(11)\n",
      "memory usage: 26.9 MB\n",
      "\n",
      "--- UsnJrnl Initial Inspection ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimeStamp(UTC+8)</th>\n",
       "      <th>USN</th>\n",
       "      <th>File/Directory Name</th>\n",
       "      <th>FullPath</th>\n",
       "      <th>EventInfo</th>\n",
       "      <th>SourceInfo</th>\n",
       "      <th>FileAttribute</th>\n",
       "      <th>Carving Flag</th>\n",
       "      <th>FileReferenceNumber</th>\n",
       "      <th>ParentFileReferenceNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/19/23 15:12:25</td>\n",
       "      <td>1291845632</td>\n",
       "      <td>dsreg.dll.mui</td>\n",
       "      <td>\\Program Files\\WindowsApps\\Microsoft.LanguageE...</td>\n",
       "      <td>File_Closed</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Archive / Repasre_Point / Sparse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x000200000007E855</td>\n",
       "      <td>0x00060000000542FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/19/23 15:12:25</td>\n",
       "      <td>1291845720</td>\n",
       "      <td>dsregcmd.exe.mui</td>\n",
       "      <td>\\Program Files\\WindowsApps\\Microsoft.LanguageE...</td>\n",
       "      <td>File_Created / Data_Added</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Archive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x000200000007E856</td>\n",
       "      <td>0x00060000000542FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/19/23 15:12:25</td>\n",
       "      <td>1291845816</td>\n",
       "      <td>dsregcmd.exe.mui</td>\n",
       "      <td>\\Program Files\\WindowsApps\\Microsoft.LanguageE...</td>\n",
       "      <td>File_Created / Data_Added / Reparse_Point_Changed</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Archive / Repasre_Point</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x000200000007E856</td>\n",
       "      <td>0x00060000000542FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/19/23 15:12:25</td>\n",
       "      <td>1291845912</td>\n",
       "      <td>dsregcmd.exe.mui</td>\n",
       "      <td>\\Program Files\\WindowsApps\\Microsoft.LanguageE...</td>\n",
       "      <td>File_Created / Data_Added / Reparse_Point_Chan...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Archive / Repasre_Point</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x000200000007E856</td>\n",
       "      <td>0x00060000000542FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/19/23 15:12:25</td>\n",
       "      <td>1291846008</td>\n",
       "      <td>dsregcmd.exe.mui</td>\n",
       "      <td>\\Program Files\\WindowsApps\\Microsoft.LanguageE...</td>\n",
       "      <td>File_Created / Data_Added / Named_Data_Stream_...</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Archive / Repasre_Point</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0x000200000007E856</td>\n",
       "      <td>0x00060000000542FB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TimeStamp(UTC+8)         USN File/Directory Name                                           FullPath                                          EventInfo SourceInfo                     FileAttribute  Carving Flag FileReferenceNumber ParentFileReferenceNumber\n",
       "0  12/19/23 15:12:25  1291845632       dsreg.dll.mui  \\Program Files\\WindowsApps\\Microsoft.LanguageE...                                        File_Closed     Normal  Archive / Repasre_Point / Sparse           NaN  0x000200000007E855        0x00060000000542FB\n",
       "1  12/19/23 15:12:25  1291845720    dsregcmd.exe.mui  \\Program Files\\WindowsApps\\Microsoft.LanguageE...                          File_Created / Data_Added     Normal                           Archive           NaN  0x000200000007E856        0x00060000000542FB\n",
       "2  12/19/23 15:12:25  1291845816    dsregcmd.exe.mui  \\Program Files\\WindowsApps\\Microsoft.LanguageE...  File_Created / Data_Added / Reparse_Point_Changed     Normal           Archive / Repasre_Point           NaN  0x000200000007E856        0x00060000000542FB\n",
       "3  12/19/23 15:12:25  1291845912    dsregcmd.exe.mui  \\Program Files\\WindowsApps\\Microsoft.LanguageE...  File_Created / Data_Added / Reparse_Point_Chan...     Normal           Archive / Repasre_Point           NaN  0x000200000007E856        0x00060000000542FB\n",
       "4  12/19/23 15:12:25  1291846008    dsregcmd.exe.mui  \\Program Files\\WindowsApps\\Microsoft.LanguageE...  File_Created / Data_Added / Named_Data_Stream_...     Normal           Archive / Repasre_Point           NaN  0x000200000007E856        0x00060000000542FB"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 316817 entries, 0 to 316816\n",
      "Columns: 10 entries, TimeStamp(UTC+8) to ParentFileReferenceNumber\n",
      "dtypes: float64(1), int64(1), object(8)\n",
      "memory usage: 187.8 MB\n"
     ]
    }
   ],
   "source": [
    "# Check LogFile structure\n",
    "print(\"\\n--- LogFile Initial Inspection ---\")\n",
    "display(df_log.head())\n",
    "df_log.info(verbose=False, memory_usage='deep')\n",
    "\n",
    "# Check UsnJrnl structure\n",
    "print(\"\\n--- UsnJrnl Initial Inspection ---\")\n",
    "display(df_usn.head())\n",
    "df_usn.info(verbose=False, memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afb4332",
   "metadata": {},
   "source": [
    "## LogFile Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbfd536",
   "metadata": {},
   "source": [
    "### 1. Standardize Column Names\n",
    "First, we must standardize the column names for uniformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e5fffee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New LogFile Columns: ['lsn', 'eventtime', 'event', 'detail', 'filedirectoryname', 'fullpath', 'creationtime', 'modifiedtime', 'mftmodifiedtime', 'accessedtime', 'redo', 'targetvcn', 'clusterindex']\n"
     ]
    }
   ],
   "source": [
    "# 1. Standardize column names: lowercase, remove special characters/parentheses, replace spaces with underscores.\n",
    "df_log.columns = (\n",
    "    df_log.columns\n",
    "    .str.lower()\n",
    "    .str.replace(r'\\(.*?\\)', '', regex=True) # Remove anything in parentheses (like '(UTC+8)')\n",
    "    .str.replace('[^a-z0-9_]', '', regex=True) # Remove other non-alphanumeric chars (like slashes)\n",
    "    .str.replace(' ', '_', regex=False)\n",
    "    .str.replace('__', '_', regex=False) # Handle double underscores if they result\n",
    "    .str.strip('_') # Remove leading/trailing underscores\n",
    ")\n",
    "\n",
    "# Display the new, clean column names\n",
    "print(\"New LogFile Columns:\", df_log.columns.tolist())\n",
    "\n",
    "# Rename specific columns for clarity if needed (e.g., 'eventdetail' is a good name already)\n",
    "# If your column is now just 'eventdetail', you are good to go.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ff6170",
   "metadata": {},
   "source": [
    "### 2.1 Check for Missing Values for all columns\n",
    "Now we can accurately check for missing values in all columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "af7b1ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for LogFile (Total Rows: 39077) ---\n",
      "--------------------------------------------------\n",
      "Columns with Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>detail</th>\n",
       "      <td>26678</td>\n",
       "      <td>68.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventtime</th>\n",
       "      <td>22815</td>\n",
       "      <td>58.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event</th>\n",
       "      <td>19577</td>\n",
       "      <td>50.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creationtime</th>\n",
       "      <td>10897</td>\n",
       "      <td>27.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modifiedtime</th>\n",
       "      <td>10897</td>\n",
       "      <td>27.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mftmodifiedtime</th>\n",
       "      <td>10897</td>\n",
       "      <td>27.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accessedtime</th>\n",
       "      <td>10897</td>\n",
       "      <td>27.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullpath</th>\n",
       "      <td>4315</td>\n",
       "      <td>11.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filedirectoryname</th>\n",
       "      <td>447</td>\n",
       "      <td>1.140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Missing Count  Missing Percentage\n",
       "detail                     26678              68.270\n",
       "eventtime                  22815              58.380\n",
       "event                      19577              50.100\n",
       "creationtime               10897              27.890\n",
       "modifiedtime               10897              27.890\n",
       "mftmodifiedtime            10897              27.890\n",
       "accessedtime               10897              27.890\n",
       "fullpath                    4315              11.040\n",
       "filedirectoryname            447               1.140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of entries\n",
    "total_rows = len(df_log)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for LogFile (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_log.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"ðŸŽ‰ Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d6bfa2",
   "metadata": {},
   "source": [
    "#### 2.1.1 Removing empty values on event\n",
    "We must remove rows with empty rows in the **event** column because this information provides the causation (the file action) that links timestamps together. For a thesis on timestomping detection, removing eventless records ensures the ML model only trains on high-integrity data, preventing unreliable feature creation and minimizing the risk of low-confidence or false-positive reports in your prototype's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1b154d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LogFile Event Detail Cleaning ---\n",
      "Total rows before cleaning: 39077\n",
      "Rows with missing 'event': 19577\n",
      "Percentage missing: 50.10%\n",
      "--------------------------------------------------\n",
      "âœ… Successfully dropped 19577 rows.\n",
      "Rows remaining in LogFile: 19500\n"
     ]
    }
   ],
   "source": [
    "# 1. Identify the critical column\n",
    "event_col = 'event'\n",
    "\n",
    "# 2. Check for missing values in the 'event' column\n",
    "total_rows = len(df_log)\n",
    "missing_event_count = df_log[event_col].isna().sum()\n",
    "\n",
    "print(f\"--- LogFile Event Detail Cleaning ---\")\n",
    "print(f\"Total rows before cleaning: {total_rows}\")\n",
    "print(f\"Rows with missing '{event_col}': {missing_event_count}\")\n",
    "print(f\"Percentage missing: {missing_event_count / total_rows * 100:.2f}%\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# 3. Drop rows where the 'event' column is NaN\n",
    "# We use inplace=True to modify the DataFrame directly\n",
    "if missing_event_count > 0:\n",
    "    df_log.dropna(subset=[event_col], inplace=True)\n",
    "    \n",
    "    # 4. Verification\n",
    "    rows_dropped = missing_event_count\n",
    "    rows_remaining = len(df_log)\n",
    "    \n",
    "    print(f\"âœ… Successfully dropped {rows_dropped} rows.\")\n",
    "    print(f\"Rows remaining in LogFile: {rows_remaining}\")\n",
    "else:\n",
    "    print(\"Column 'event' is fully populated. No rows were dropped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ac06ea",
   "metadata": {},
   "source": [
    "#### 2.1.2 Dropping detail column \n",
    "Retaining it would require complex and inefficient Natural Language Processing (NLP) techniques, whereas all necessary context is already captured by the event and timestamp columns, justifying its removal for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "68fe3afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully dropped the 'detail' column.\n",
      "Columns remaining: ['lsn', 'eventtime', 'event', 'filedirectoryname', 'fullpath', 'creationtime', 'modifiedtime', 'mftmodifiedtime', 'accessedtime', 'redo', 'targetvcn', 'clusterindex']\n"
     ]
    }
   ],
   "source": [
    "# Define the column to be dropped\n",
    "detail_col = 'detail'\n",
    "\n",
    "if detail_col in df_log.columns:\n",
    "    # Drop the 'detail' column permanently\n",
    "    df_log.drop(columns=[detail_col], inplace=True)\n",
    "    \n",
    "    print(f\"âœ… Successfully dropped the '{detail_col}' column.\")\n",
    "    print(f\"Columns remaining: {list(df_log.columns)}\")\n",
    "else:\n",
    "    print(f\"Column '{detail_col}' was already dropped or not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1cc6ae",
   "metadata": {},
   "source": [
    "### 2.2 Check for Missing Values for all columns\n",
    "Checking if the dropped values of **event** is effective, and address more columns to clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "92b10059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for LogFile (Total Rows: 19500) ---\n",
      "--------------------------------------------------\n",
      "Columns with Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>creationtime</th>\n",
       "      <td>10897</td>\n",
       "      <td>55.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modifiedtime</th>\n",
       "      <td>10897</td>\n",
       "      <td>55.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mftmodifiedtime</th>\n",
       "      <td>10897</td>\n",
       "      <td>55.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accessedtime</th>\n",
       "      <td>10897</td>\n",
       "      <td>55.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eventtime</th>\n",
       "      <td>8031</td>\n",
       "      <td>41.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullpath</th>\n",
       "      <td>4254</td>\n",
       "      <td>21.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filedirectoryname</th>\n",
       "      <td>447</td>\n",
       "      <td>2.290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Missing Count  Missing Percentage\n",
       "creationtime               10897              55.880\n",
       "modifiedtime               10897              55.880\n",
       "mftmodifiedtime            10897              55.880\n",
       "accessedtime               10897              55.880\n",
       "eventtime                   8031              41.180\n",
       "fullpath                    4254              21.820\n",
       "filedirectoryname            447               2.290"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of entries\n",
    "total_rows = len(df_log)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for LogFile (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_log.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"ðŸŽ‰ Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa22248",
   "metadata": {},
   "source": [
    "#### 2.2.1 eventtime Imputation starting with creationtime \n",
    "We are imputing the missing **eventtime** to ensure every record has a chronological anchor, which is essential for sequencing events and calculating time deltas for the ML model. We use the reliable timestamps (**creationtime**, **modifiedtime**, and **mftmodifiedtime**) for this, but intentionally exclude **accessedtime** from imputation because its high unreliability risks corrupting the logical chronological order. We keep the **accessedtime** column as a separate feature because its inconsistency or presence might still serve as a detectable signal that the ML model can learn to associate with anomalous (timestomped) file activity. \n",
    "\n",
    "In the first layer of imputation, we start with creationtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "388ac19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing 'eventtime' before imputation: 8031\n",
      "Rows imputed (filled): 2346\n",
      "Remaining missing 'eventtime' after imputation: 5685\n",
      "\n",
      "Note: Some rows still have missing 'eventtime'. This means their corresponding 'creationtime' was also missing.\n",
      "\n",
      "Sample of rows (first 5) to show the filled column:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eventtime</th>\n",
       "      <th>creationtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          eventtime      creationtime\n",
       "1  12/23/23 0:14:23  12/23/23 0:14:23\n",
       "2  12/23/23 0:14:23               NaN\n",
       "3  12/23/23 0:14:23               NaN\n",
       "5  12/23/23 0:14:23  12/23/23 0:14:23\n",
       "6  12/23/23 0:14:23               NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Standardize column names (if not done in the previous cell to ensure reliability)\n",
    "df_log.columns = (\n",
    "    df_log.columns\n",
    "    .str.lower()\n",
    "    .str.replace(r'\\(.*?\\)', '', regex=True) # Remove anything in parentheses\n",
    "    .str.replace('[^a-z0-9_]', '', regex=True)\n",
    "    .str.replace(' ', '_', regex=False)\n",
    "    .str.strip('_')\n",
    ")\n",
    "\n",
    "# Define the columns (using the exact names found: 'eventtime' and 'creationtime')\n",
    "event_time_col = 'eventtime'\n",
    "creation_time_col = 'creationtime'\n",
    "\n",
    "# 2. Check current state of eventtime\n",
    "initial_missing_count = df_log[event_time_col].isna().sum()\n",
    "print(f\"Rows with missing '{event_time_col}' before imputation: {initial_missing_count}\")\n",
    "\n",
    "if initial_missing_count > 0:\n",
    "    # 3. Impute missing 'eventtime' using 'creationtime'\n",
    "    # We use .fillna() and provide the entire 'creationtime' Series as the filling value.\n",
    "    df_log[event_time_col] = df_log[event_time_col].fillna(df_log[creation_time_col])\n",
    "\n",
    "    # 4. Verification Check\n",
    "    final_missing_count = df_log[event_time_col].isna().sum()\n",
    "    rows_imputed = initial_missing_count - final_missing_count\n",
    "\n",
    "    print(f\"Rows imputed (filled): {rows_imputed}\")\n",
    "    print(f\"Remaining missing '{event_time_col}' after imputation: {final_missing_count}\")\n",
    "    \n",
    "    if final_missing_count > 0:\n",
    "        print(\"\\nNote: Some rows still have missing 'eventtime'. This means their corresponding 'creationtime' was also missing.\")\n",
    "        # If necessary, we would drop these remaining rows in a later step if time data is non-negotiable.\n",
    "\n",
    "    # 5. Display a sample of imputed rows (where the value was previously NaN)\n",
    "    # This requires running the verification check on the original data, but we can show the fill-in effect:\n",
    "    print(\"\\nSample of rows (first 5) to show the filled column:\")\n",
    "    display(df_log[[event_time_col, creation_time_col]].head())\n",
    "\n",
    "else:\n",
    "    print(f\"Column '{event_time_col}' is already complete. No imputation was performed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34784ac",
   "metadata": {},
   "source": [
    "##### 2.2.1.2 EventTime Further Adjustment: Timestamp existence checking & Imputation of Latest Available Time. \n",
    "If **creationtime** is also missing, use the latest of the remaining valid timestamps, except **accessedtime** for imputation. This is the most conservative estimate for the transaction commit time, avoiding the bias of timestomping. But we should check first if other timestamps are existing when creationtime isn't. If they don't we can drop the row as they don't exist any timestamps, thus no relevant data for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a052b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 1: Conditional Early Drop ---\n",
      "Total rows where 'creationtime' is missing: 10897\n",
      "Rows where ALL 5 timestamps are ALSO missing: 5685\n",
      "Percentage of creationtime-missing rows where all others are also missing: 52.17%\n",
      "\n",
      "Removed 5685 rows that were missing ALL 5 timestamps.\n",
      "Rows remaining in LogFile: 13815\n",
      "\n",
      "--- Step 2: Imputation Priority 2 ---\n",
      "No further 'eventtime' NaNs found. Cleaning complete. âœ…\n"
     ]
    }
   ],
   "source": [
    "# Define all relevant timestamp columns\n",
    "event_time_col = 'eventtime'\n",
    "creation_time_col = 'creationtime'\n",
    "# Note: accessedtime is NOT included in the reliable list for IMPUTATION, but it IS used for the initial drop check\n",
    "reliable_ntfs_timestamps = ['creationtime', 'modifiedtime', 'mftmodifiedtime'] \n",
    "all_time_cols = [event_time_col] + reliable_ntfs_timestamps + ['accessedtime'] # 5 total columns\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "## Step 1: Conditional Early Drop (Based on Forensic Pattern)\n",
    "# -------------------------------------------------------------\n",
    "print(\"--- Step 1: Conditional Early Drop ---\")\n",
    "\n",
    "# 1. Filter the DataFrame for rows where 'creationtime' is missing (NaN)\n",
    "creation_time_missing_df = df_log[df_log[creation_time_col].isna()]\n",
    "total_creation_time_missing = len(creation_time_missing_df)\n",
    "\n",
    "# 2. Check the condition: Are ALL 5 time columns missing in this subset?\n",
    "# This identifies rows that are truly time-less (missing eventtime, creationtime, modifiedtime, mftmodifiedtime, and accessedtime)\n",
    "all_time_missing_mask = df_log[all_time_cols].isna().all(axis=1)\n",
    "count_all_empty = all_time_missing_mask.sum()\n",
    "\n",
    "# 3. Report the compelling forensic finding (similar to your request)\n",
    "print(f\"Total rows where '{creation_time_col}' is missing: {total_creation_time_missing}\")\n",
    "\n",
    "# Only calculate percentage if there are missing creationtime rows AND they all align with the 'all empty' count\n",
    "if total_creation_time_missing > 0 and count_all_empty == total_creation_time_missing:\n",
    "    print(f\"Rows where ALL 5 timestamps are ALSO missing: {count_all_empty}\")\n",
    "    print(f\"Percentage of creationtime-missing rows where all others are also missing: 100.00%\")\n",
    "elif total_creation_time_missing > 0:\n",
    "    # If not 100%, show the actual percentage\n",
    "    percentage = (count_all_empty / total_creation_time_missing) * 100\n",
    "    print(f\"Rows where ALL 5 timestamps are ALSO missing: {count_all_empty}\")\n",
    "    print(f\"Percentage of creationtime-missing rows where all others are also missing: {percentage:.2f}%\")\n",
    "else:\n",
    "    print(\"No rows found where 'creationtime' is missing.\")\n",
    "\n",
    "\n",
    "if count_all_empty > 0:\n",
    "    # Drop these rows immediately\n",
    "    df_log.drop(df_log[all_time_missing_mask].index, inplace=True)\n",
    "    \n",
    "    print(f\"\\nRemoved {count_all_empty} rows that were missing ALL 5 timestamps.\")\n",
    "    print(f\"Rows remaining in LogFile: {len(df_log)}\")\n",
    "else:\n",
    "    print(\"No completely time-less rows found. Proceeding to imputation.\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "## Step 2: Imputation Priority 2 (Latest of Reliable Times)\n",
    "# -------------------------------------------------------------\n",
    "# Note: Imputation Priority 1 (eventtime with creationtime) is assumed to have run previously.\n",
    "print(\"\\n--- Step 2: Imputation Priority 2 ---\")\n",
    "remaining_missing_before = df_log[event_time_col].isna().sum()\n",
    "\n",
    "if remaining_missing_before > 0:\n",
    "    \n",
    "    # 1. Create a temporary 'LatestTime' column, using only the *reliable* subset\n",
    "    df_log['latest_reliable_time_temp'] = df_log[reliable_ntfs_timestamps].max(axis=1)\n",
    "\n",
    "    # 2. Fill the remaining missing 'eventtime' values with this latest available time\n",
    "    df_log[event_time_col] = df_log[event_time_col].fillna(df_log['latest_reliable_time_temp'])\n",
    "\n",
    "    # Calculate and report results\n",
    "    rows_imputed_p2 = remaining_missing_before - df_log[event_time_col].isna().sum()\n",
    "\n",
    "    print(f\"Imputed remaining 'eventtime' with the LATEST RELIABLE available time. Rows filled: {rows_imputed_p2}\")\n",
    "    \n",
    "    # Drop the temporary column\n",
    "    df_log.drop(columns=['latest_reliable_time_temp'], inplace=True)\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    ## Step 3: Final Clean-up (Drop residual empty records)\n",
    "    # -------------------------------------------------------------\n",
    "    final_missing_count = df_log[event_time_col].isna().sum()\n",
    "    print(\"\\n--- Step 3: Final Clean-up ---\")\n",
    "\n",
    "    # ðŸŽ¯ Added Print: Show the final count of NaNs before the last drop\n",
    "    print(f\"Final EventTime NaNs before drop: {final_missing_count}\")\n",
    "\n",
    "    if final_missing_count > 0:\n",
    "        df_log.dropna(subset=[event_time_col], inplace=True)\n",
    "        \n",
    "        print(f\"Final drop: Removed {final_missing_count} residual rows.\")\n",
    "        print(f\"Rows remaining in LogFile: {len(df_log)}.\")\n",
    "    else:\n",
    "        print(\"All records now have a valid 'eventtime'. No further time-based rows were dropped. âœ…\")\n",
    "\n",
    "else:\n",
    "    print(\"No further 'eventtime' NaNs found. Cleaning complete. âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50014aca",
   "metadata": {},
   "source": [
    "### 2.3 Check for Missing Values for all columns\n",
    "Checking if the dropped values of **eventtime** is effective, and address more columns to clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e6ea6a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for LogFile (Total Rows: 13815) ---\n",
      "--------------------------------------------------\n",
      "Columns with Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>creationtime</th>\n",
       "      <td>5212</td>\n",
       "      <td>37.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modifiedtime</th>\n",
       "      <td>5212</td>\n",
       "      <td>37.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mftmodifiedtime</th>\n",
       "      <td>5212</td>\n",
       "      <td>37.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accessedtime</th>\n",
       "      <td>5212</td>\n",
       "      <td>37.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fullpath</th>\n",
       "      <td>3622</td>\n",
       "      <td>26.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filedirectoryname</th>\n",
       "      <td>158</td>\n",
       "      <td>1.140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Missing Count  Missing Percentage\n",
       "creationtime                5212              37.730\n",
       "modifiedtime                5212              37.730\n",
       "mftmodifiedtime             5212              37.730\n",
       "accessedtime                5212              37.730\n",
       "fullpath                    3622              26.220\n",
       "filedirectoryname            158               1.140"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of entries\n",
    "total_rows = len(df_log)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for LogFile (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_log.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"ðŸŽ‰ Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a728eeb",
   "metadata": {},
   "source": [
    "#### 2.3.1 Dropping Rows with Empty Timestamps Across creationtime, modifiedtime, mftmodifiedtime, and accessedtime \n",
    "Upon observing the presented data, if there are an equal amount of empty rows across all timestamps, this could mean that they are the same rows. Any row that doesn't have any timestamps regardless if they have other information, could not provide any relevant information to us or a model. Thus, we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2efaa508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Unusable Time Records Drop Check ---\n",
      "Total rows before check: 13815\n",
      "Rows with valid 'eventtime' but NO NTFS timestamps to compare: 5212\n",
      "âœ… Successfully dropped 5212 records due to insufficient timestamp evidence.\n",
      "Rows remaining in LogFile: 8603\n"
     ]
    }
   ],
   "source": [
    "# Define the columns (assuming previous cleaning steps left them as datetime objects with NaT for missing)\n",
    "event_time_col = 'eventtime'\n",
    "ntfs_timestamps = ['creationtime', 'modifiedtime', 'mftmodifiedtime', 'accessedtime']\n",
    "\n",
    "# 1. Create a mask for the rows that meet the condition\n",
    "# Condition A: eventtime is NOT missing (~df_log[event_time_col].isna())\n",
    "# Condition B: ALL four NTFS timestamps ARE missing (df_log[ntfs_timestamps].isna().all(axis=1))\n",
    "unusable_time_mask = (\n",
    "    (~df_log[event_time_col].isna()) & \n",
    "    (df_log[ntfs_timestamps].isna().all(axis=1))\n",
    ")\n",
    "\n",
    "# 2. Check and Report\n",
    "rows_to_drop = unusable_time_mask.sum()\n",
    "initial_total_rows = len(df_log)\n",
    "\n",
    "print(\"--- Unusable Time Records Drop Check ---\")\n",
    "print(f\"Total rows before check: {initial_total_rows}\")\n",
    "print(f\"Rows with valid 'eventtime' but NO NTFS timestamps to compare: {rows_to_drop}\")\n",
    "\n",
    "# 3. Conditional Drop\n",
    "if rows_to_drop > 0:\n",
    "    df_log.drop(df_log[unusable_time_mask].index, inplace=True)\n",
    "    \n",
    "    rows_remaining = len(df_log)\n",
    "    print(f\"âœ… Successfully dropped {rows_to_drop} records due to insufficient timestamp evidence.\")\n",
    "    print(f\"Rows remaining in LogFile: {rows_remaining}\")\n",
    "else:\n",
    "    print(\"No records found with valid 'eventtime' but missing all four NTFS timestamps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8630156",
   "metadata": {},
   "source": [
    "### 2.4 Check for Missing Values for all columns\n",
    "Checking if the dropped values of **creationtime**, **modifiedtime**, **mftmodifiedtime**, **accessedtime**, is effective, and address more columns to clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "386ac6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for LogFile (Total Rows: 8603) ---\n",
      "--------------------------------------------------\n",
      "Columns with Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fullpath</th>\n",
       "      <td>3031</td>\n",
       "      <td>35.230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Missing Count  Missing Percentage\n",
       "fullpath           3031              35.230"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Check the total number of entries\n",
    "total_rows = len(df_log)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for LogFile (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_log.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"ðŸŽ‰ Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99aada7",
   "metadata": {},
   "source": [
    "#### 2.4.1 Dropping Empty filedirectoryname Rows \n",
    "This is because a log record that has timestamps and an event, but doesn't identify the file it applies to, is forensically vague. It tells you something happened at a certain time but not to what."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a8b8ff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- File Directory Name Cleaning ---\n",
      "Total rows before cleaning: 8603\n",
      "Rows with missing 'filedirectoryname': 0\n",
      "Column 'filedirectoryname' is fully populated. No rows were dropped.\n"
     ]
    }
   ],
   "source": [
    "# Define the file identifier column\n",
    "file_name_col = 'filedirectoryname'\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "## Step 1: Check and Report Missing File Names\n",
    "# -------------------------------------------------------------\n",
    "initial_total_rows = len(df_log)\n",
    "missing_file_count = df_log[file_name_col].isna().sum()\n",
    "\n",
    "print(\"--- File Directory Name Cleaning ---\")\n",
    "print(f\"Total rows before cleaning: {initial_total_rows}\")\n",
    "print(f\"Rows with missing '{file_name_col}': {missing_file_count}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "## Step 2: Conditional Drop\n",
    "# -------------------------------------------------------------\n",
    "if missing_file_count > 0:\n",
    "    # Drop rows where the file directory name is NaN (missing the primary grouping key)\n",
    "    # We drop them in place as they are forensically useless for this analysis.\n",
    "    df_log.dropna(subset=[file_name_col], inplace=True)\n",
    "    \n",
    "    # 3. Verification\n",
    "    rows_remaining = len(df_log)\n",
    "    rows_dropped = missing_file_count\n",
    "    \n",
    "    print(f\"âœ… Successfully dropped {rows_dropped} rows due to missing file identifier.\")\n",
    "    print(f\"Rows remaining in LogFile: {rows_remaining}\")\n",
    "else:\n",
    "    print(f\"Column '{file_name_col}' is fully populated. No rows were dropped.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6edca0e",
   "metadata": {},
   "source": [
    "### 2.5 Check for Missing Values for all columns\n",
    "Checking if the dropped values of **filedirectoryname** is effective, and address more columns to clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "69e3ddca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for LogFile (Total Rows: 8603) ---\n",
      "--------------------------------------------------\n",
      "Columns with Missing Values:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fullpath</th>\n",
       "      <td>3031</td>\n",
       "      <td>35.230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Missing Count  Missing Percentage\n",
       "fullpath           3031              35.230"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Check the total number of entries\n",
    "total_rows = len(df_log)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for LogFile (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_log.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"ðŸŽ‰ Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d21d2",
   "metadata": {},
   "source": [
    "#### 2.5.1 Imputing filedirectoryname to empty fullpath \n",
    "By filling the missing fullpath with the filedirectoryname and creating a binary flag, we maintain the record's primary timing evidence while informing the model that its location data was suspect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d292cef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FullPath Imputation and Flagging ---\n",
      "Rows with missing 'fullpath' before imputation: 3031\n",
      "âœ… Created binary flag column 'missing_fullpath_flag' to mark original NaNs.\n",
      "Imputed 3031 rows using 'filedirectoryname'.\n",
      "Remaining missing 'fullpath' after imputation: 0\n"
     ]
    }
   ],
   "source": [
    "# Define columns\n",
    "fullpath_col = 'fullpath'\n",
    "filename_col = 'filedirectoryname'\n",
    "flag_col = 'missing_fullpath_flag'\n",
    "\n",
    "# 1. Check initial state\n",
    "initial_missing_count = df_log[fullpath_col].isna().sum()\n",
    "\n",
    "print(\"--- FullPath Imputation and Flagging ---\")\n",
    "print(f\"Rows with missing '{fullpath_col}' before imputation: {initial_missing_count}\")\n",
    "\n",
    "if initial_missing_count > 0:\n",
    "    # 2. Create the binary flag column\n",
    "    # Flag is 1 where fullpath was originally missing, 0 otherwise. This is a valuable feature for the ML model.\n",
    "    df_log[flag_col] = df_log[fullpath_col].isna().astype(int)\n",
    "    print(f\"âœ… Created binary flag column '{flag_col}' to mark original NaNs.\")\n",
    "\n",
    "    # 3. Impute missing fullpath values with the file name\n",
    "    df_log[fullpath_col] = df_log[fullpath_col].fillna(df_log[filename_col])\n",
    "\n",
    "    # 4. Report the result\n",
    "    final_missing_count = df_log[fullpath_col].isna().sum()\n",
    "    rows_imputed = initial_missing_count - final_missing_count\n",
    "    \n",
    "    print(f\"Imputed {rows_imputed} rows using '{filename_col}'.\")\n",
    "    print(f\"Remaining missing '{fullpath_col}' after imputation: {final_missing_count}\")\n",
    "\n",
    "    # 5. Final cleanup: Drop residual NaNs (where both fullpath and filename were NaN)\n",
    "    if final_missing_count > 0:\n",
    "        df_log.dropna(subset=[fullpath_col], inplace=True)\n",
    "        print(f\"Final drop: Removed {final_missing_count} rows where both fullpath and filename were NaN.\")\n",
    "        print(f\"Rows remaining in LogFile: {len(df_log)}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Column '{fullpath_col}' is fully populated. No imputation needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5269114c",
   "metadata": {},
   "source": [
    "### 2.6 Check for Missing Values for all columns\n",
    "Checking if the values of **fullpath** is effective, and address more columns to clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "89274253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Missing Value Report for LogFile (Total Rows: 8603) ---\n",
      "--------------------------------------------------\n",
      "ðŸŽ‰ Congratulations! No missing values found in any column.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Check the total number of entries\n",
    "total_rows = len(df_log)\n",
    "\n",
    "# Print total rows for context\n",
    "print(f\"--- Missing Value Report for LogFile (Total Rows: {total_rows}) ---\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Use a concise method to count NaNs for all columns\n",
    "missing_values_report = df_log.isnull().sum()\n",
    "missing_percentage_report = (missing_values_report / total_rows) * 100\n",
    "\n",
    "# Combine the count and percentage into a single DataFrame for clean viewing\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values_report,\n",
    "    'Missing Percentage': missing_percentage_report.round(2)\n",
    "})\n",
    "\n",
    "# Filter to show only columns with at least one missing value\n",
    "# (Optional: remove this line if you want to see all columns)\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
    "\n",
    "# Sort by the number of missing values (descending)\n",
    "missing_df.sort_values(by='Missing Count', ascending=False, inplace=True)\n",
    "\n",
    "# Display the report\n",
    "if missing_df.empty:\n",
    "    print(\"ðŸŽ‰ Congratulations! No missing values found in any column.\")\n",
    "else:\n",
    "    print(\"Columns with Missing Values:\")\n",
    "    display(missing_df)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2934a092",
   "metadata": {},
   "source": [
    "### Present the cleaned LogFile table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "75bf5d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LogFile Initial Inspection ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lsn</th>\n",
       "      <th>eventtime</th>\n",
       "      <th>event</th>\n",
       "      <th>filedirectoryname</th>\n",
       "      <th>fullpath</th>\n",
       "      <th>creationtime</th>\n",
       "      <th>modifiedtime</th>\n",
       "      <th>mftmodifiedtime</th>\n",
       "      <th>accessedtime</th>\n",
       "      <th>redo</th>\n",
       "      <th>targetvcn</th>\n",
       "      <th>clusterindex</th>\n",
       "      <th>missing_fullpath_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8713791717</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>File Creation</td>\n",
       "      <td>dropboxstatus-connecting@3x.png</td>\n",
       "      <td>\\Program Files (x86)\\Dropbox\\Client\\189.4.8395...</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>Initialize File Record Segment</td>\n",
       "      <td>0x170EF</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8713792451</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>File Creation</td>\n",
       "      <td>dropboxstatus-idle.png</td>\n",
       "      <td>\\Program Files (x86)\\Dropbox\\Client\\189.4.8395...</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>Initialize File Record Segment</td>\n",
       "      <td>0x170F0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8713793177</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>File Creation</td>\n",
       "      <td>dropboxstatus-idle@1p25x.png</td>\n",
       "      <td>\\Program Files (x86)\\Dropbox\\Client\\189.4.8395...</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>Initialize File Record Segment</td>\n",
       "      <td>0x171DC</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8713793904</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>File Creation</td>\n",
       "      <td>dropboxstatus-idle@1p5x.png</td>\n",
       "      <td>\\Program Files (x86)\\Dropbox\\Client\\189.4.8395...</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>Initialize File Record Segment</td>\n",
       "      <td>0x1727B</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8713794646</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>File Creation</td>\n",
       "      <td>dropboxstatus-idle@1p75x.png</td>\n",
       "      <td>\\Program Files (x86)\\Dropbox\\Client\\189.4.8395...</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>12/23/23 0:14:23</td>\n",
       "      <td>Initialize File Record Segment</td>\n",
       "      <td>0x17281</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lsn         eventtime          event                filedirectoryname                                           fullpath      creationtime      modifiedtime   mftmodifiedtime      accessedtime                            redo targetvcn  clusterindex  missing_fullpath_flag\n",
       "1   8713791717  12/23/23 0:14:23  File Creation  dropboxstatus-connecting@3x.png  \\Program Files (x86)\\Dropbox\\Client\\189.4.8395...  12/23/23 0:14:23  12/23/23 0:14:23  12/23/23 0:14:23  12/23/23 0:14:23  Initialize File Record Segment   0x170EF             6                      0\n",
       "5   8713792451  12/23/23 0:14:23  File Creation           dropboxstatus-idle.png  \\Program Files (x86)\\Dropbox\\Client\\189.4.8395...  12/23/23 0:14:23  12/23/23 0:14:23  12/23/23 0:14:23  12/23/23 0:14:23  Initialize File Record Segment   0x170F0             0                      0\n",
       "9   8713793177  12/23/23 0:14:23  File Creation     dropboxstatus-idle@1p25x.png  \\Program Files (x86)\\Dropbox\\Client\\189.4.8395...  12/23/23 0:14:23  12/23/23 0:14:23  12/23/23 0:14:23  12/23/23 0:14:23  Initialize File Record Segment   0x171DC             2                      0\n",
       "13  8713793904  12/23/23 0:14:23  File Creation      dropboxstatus-idle@1p5x.png  \\Program Files (x86)\\Dropbox\\Client\\189.4.8395...  12/23/23 0:14:23  12/23/23 0:14:23  12/23/23 0:14:23  12/23/23 0:14:23  Initialize File Record Segment   0x1727B             0                      0\n",
       "17  8713794646  12/23/23 0:14:23  File Creation     dropboxstatus-idle@1p75x.png  \\Program Files (x86)\\Dropbox\\Client\\189.4.8395...  12/23/23 0:14:23  12/23/23 0:14:23  12/23/23 0:14:23  12/23/23 0:14:23  Initialize File Record Segment   0x17281             4                      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8603 entries, 1 to 39075\n",
      "Columns: 13 entries, lsn to missing_fullpath_flag\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 6.2 MB\n",
      "LogFile data loaded successfully. Shape: (8603, 13)\n"
     ]
    }
   ],
   "source": [
    "# Check LogFile structure\n",
    "print(\"\\n--- LogFile Initial Inspection ---\")\n",
    "display(df_log.head())\n",
    "df_log.info(verbose=False, memory_usage='deep')\n",
    "print(f\"LogFile data loaded successfully. Shape: {df_log.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2259700e",
   "metadata": {},
   "source": [
    "### Exporting the Cleaned LogFile to data/processed/phase 1 - cleaning folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "230669cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final formatted table successfully exported to: data/processed/phase 1 - cleaning/01-PE-LogFile-Cleaned.csv\n",
      "Note: Export was optimized to avoid unnecessary date parsing warnings.\n"
     ]
    }
   ],
   "source": [
    "# Observe the format [Sub-Folder Number]-PE-LogFile-Cleaned.csv for consistency \n",
    "# Example: 01-PE-LogFile-Cleaned.csv\n",
    "\n",
    "# Define the target folder path and filename\n",
    "folder_path = 'data/processed/phase 1 - cleaning'\n",
    "filename = '01-PE-LogFile-Cleaned.csv'\n",
    "full_output_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Define the columns that need formatting\n",
    "time_cols = ['eventtime', 'creationtime', 'modifiedtime', 'mftmodifiedtime', 'accessedtime']\n",
    "\n",
    "# 1. Create a COPY of the DataFrame for string formatting\n",
    "df_export = df_log.copy()\n",
    "\n",
    "# 2. Convert all time columns to the desired string format\n",
    "for col in time_cols:\n",
    "    if col in df_export.columns:\n",
    "        # ðŸŽ¯ EFFICIENT FIX: Safely apply the string format only if the column is currently a datetime dtype.\n",
    "        # This avoids the slow re-parsing and the UserWarning.\n",
    "        if pd.api.types.is_datetime64_any_dtype(df_export[col]):\n",
    "            df_export[col] = df_export[col].dt.strftime('%m/%d/%Y %H:%M:%S')\n",
    "        # ELSE: If it's a string/object type (like NaT converted to a string), we leave it alone.\n",
    "            \n",
    "# 3. Ensure the folder exists\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# 4. Export the formatted DataFrame to CSV with UTF-8 encoding\n",
    "df_export.to_csv(full_output_path, index=False, encoding='utf-8')\n",
    "\n",
    "print(f\"âœ… Final formatted table successfully exported to: {full_output_path}\")\n",
    "print(\"Note: Export was optimized to avoid unnecessary date parsing warnings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4682598",
   "metadata": {},
   "source": [
    "## UsnJrnl Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e9818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Standardize column names: lowercase, remove special characters/parentheses, replace spaces with underscores.\n",
    "df_log.columns = (\n",
    "    df_log.columns\n",
    "    .str.lower()\n",
    "    .str.replace(r'\\(.*?\\)', '', regex=True) # Remove anything in parentheses (like '(UTC+8)')\n",
    "    .str.replace('[^a-z0-9_]', '', regex=True) # Remove other non-alphanumeric chars (like slashes)\n",
    "    .str.replace(' ', '_', regex=False)\n",
    "    .str.replace('__', '_', regex=False) # Handle double underscores if they result\n",
    "    .str.strip('_') # Remove leading/trailing underscores\n",
    ")\n",
    "\n",
    "# Display the new, clean column names\n",
    "print(\"New LogFile Columns:\", df_log.columns.tolist())\n",
    "\n",
    "# Rename specific columns for clarity if needed (e.g., 'eventdetail' is a good name already)\n",
    "# If your column is now just 'eventdetail', you are good to go.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
